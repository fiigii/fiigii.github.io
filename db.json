{"meta":{"version":1,"warehouse":"4.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/cactus/source/css/rtl.styl","path":"css/rtl.styl","modified":0,"renderable":1},{"_id":"themes/cactus/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/cactus/source/images/favicon-192x192.png","path":"images/favicon-192x192.png","modified":0,"renderable":1},{"_id":"themes/cactus/source/images/apple-touch-icon.png","path":"images/apple-touch-icon.png","modified":0,"renderable":1},{"_id":"themes/cactus/source/images/favicon.ico","path":"images/favicon.ico","modified":0,"renderable":1},{"_id":"themes/cactus/source/images/gpu.png","path":"images/gpu.png","modified":0,"renderable":1},{"_id":"themes/cactus/source/images/gpu_logo.png","path":"images/gpu_logo.png","modified":0,"renderable":1},{"_id":"themes/cactus/source/images/logo.png","path":"images/logo.png","modified":0,"renderable":1},{"_id":"themes/cactus/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/cactus/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/clipboard/clipboard.min.js","path":"lib/clipboard/clipboard.min.js","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/jquery/jquery.min.js","path":"lib/jquery/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Bold.ttf","path":"lib/meslo-LG/MesloLGL-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-BoldItalic.ttf","path":"lib/meslo-LG/MesloLGL-BoldItalic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Italic.ttf","path":"lib/meslo-LG/MesloLGL-Italic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Regular.ttf","path":"lib/meslo-LG/MesloLGL-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Bold.ttf","path":"lib/meslo-LG/MesloLGM-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-BoldItalic.ttf","path":"lib/meslo-LG/MesloLGM-BoldItalic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Italic.ttf","path":"lib/meslo-LG/MesloLGM-Italic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Regular.ttf","path":"lib/meslo-LG/MesloLGM-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Bold.ttf","path":"lib/meslo-LG/MesloLGS-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-BoldItalic.ttf","path":"lib/meslo-LG/MesloLGS-BoldItalic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Italic.ttf","path":"lib/meslo-LG/MesloLGS-Italic.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Regular.ttf","path":"lib/meslo-LG/MesloLGS-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.eot","path":"lib/vazir-font/Vazir-Black.eot","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.ttf","path":"lib/vazir-font/Vazir-Black.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff","path":"lib/vazir-font/Vazir-Black.woff","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff2","path":"lib/vazir-font/Vazir-Black.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.eot","path":"lib/vazir-font/Vazir-Bold.eot","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.ttf","path":"lib/vazir-font/Vazir-Bold.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff2","path":"lib/vazir-font/Vazir-Bold.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.eot","path":"lib/vazir-font/Vazir-Light.eot","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff","path":"lib/vazir-font/Vazir-Bold.woff","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.ttf","path":"lib/vazir-font/Vazir-Light.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff","path":"lib/vazir-font/Vazir-Light.woff","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff2","path":"lib/vazir-font/Vazir-Light.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.ttf","path":"lib/vazir-font/Vazir-Medium.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.eot","path":"lib/vazir-font/Vazir-Medium.eot","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff","path":"lib/vazir-font/Vazir-Medium.woff","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff2","path":"lib/vazir-font/Vazir-Medium.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.eot","path":"lib/vazir-font/Vazir-Regular.eot","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.ttf","path":"lib/vazir-font/Vazir-Regular.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.woff","path":"lib/vazir-font/Vazir-Regular.woff","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.woff2","path":"lib/vazir-font/Vazir-Regular.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.eot","path":"lib/vazir-font/Vazir-Thin.eot","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.ttf","path":"lib/vazir-font/Vazir-Thin.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff","path":"lib/vazir-font/Vazir-Thin.woff","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff2","path":"lib/vazir-font/Vazir-Thin.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.eot","path":"lib/vazir-font/Vazir-Variable.eot","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.ttf","path":"lib/vazir-font/Vazir-Variable.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.woff","path":"lib/vazir-font/Vazir-Variable.woff","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.woff2","path":"lib/vazir-font/Vazir-Variable.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/vazir-font/font-face.css","path":"lib/vazir-font/font-face.css","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/css/all.min.css","path":"lib/font-awesome/css/all.min.css","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.woff2","path":"lib/font-awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.ttf","path":"lib/font-awesome/webfonts/fa-regular-400.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.woff2","path":"lib/font-awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.ttf","path":"lib/font-awesome/webfonts/fa-brands-400.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.ttf","path":"lib/font-awesome/webfonts/fa-solid-900.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.woff2","path":"lib/font-awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-v4compatibility.ttf","path":"lib/font-awesome/webfonts/fa-v4compatibility.ttf","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-v4compatibility.woff2","path":"lib/font-awesome/webfonts/fa-v4compatibility.woff2","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/justified-gallery/css/justifiedGallery.min.css","path":"lib/justified-gallery/css/justifiedGallery.min.css","modified":0,"renderable":1},{"_id":"themes/cactus/source/lib/justified-gallery/js/jquery.justifiedGallery.min.js","path":"lib/justified-gallery/js/jquery.justifiedGallery.min.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"c9fe4285ce0728b0a1cb389b9bf4e3a5632b141e","modified":1681632350130},{"_id":"source/about/index.md","hash":"c2450a439e735a906f93ae5b8229822993541db1","modified":1681632350136},{"_id":"source/search/index.md","hash":"d2f7515b1b55749aad8a13e868c1a1d84b9258ae","modified":1681632350137},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs.md","hash":"52b8a56aeac7fdfcdce2bd5220de041b87558982","modified":1681632350135},{"_id":"source/_posts/.DS_Store","hash":"d3e6e921f6f2fbf68b99093a7832ffe21656664b","modified":1681632350131},{"_id":"source/_posts/Hardware-intrinsic-in-NET-Core-3-0-Introduction.md","hash":"896568f26a60c04d67ec4b2b97b29087a68c09d5","modified":1681632350136},{"_id":"source/tags/index.md","hash":"748f8276eaefb908fa8641f82c2ddc96481f6c9a","modified":1681632350138},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/.DS_Store","hash":"1b9735ded61e7ee9c0bafd6885482fadc045a274","modified":1681632350132},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS2.png","hash":"46265ff0cbc4fee49e5495abebd078fec597cd1e","modified":1681632350134},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS1.png","hash":"de7a657fee2dfcf017b4c16faab0e4a4d8f9402f","modified":1681632350134},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/ADD.png","hash":"25116658115939c638feb9cdbc477a721127d75d","modified":1681632350132},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS3.png","hash":"81b6002a1b11148df372b653e1820bb0203dd264","modified":1681632350135},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/LEA.png","hash":"94e4878e215cb6565e68f7dd34ca7edce929fe5f","modified":1681632350133},{"_id":"themes/cactus/.gitignore","hash":"72267ee409a324fc197c150b3c4bf28b87b709a8","modified":1681632350148},{"_id":"themes/cactus/.stylintrc","hash":"eb5f48e83657928cb0cbee031373b2cd36ca0083","modified":1681632350149},{"_id":"themes/cactus/.jshintrc","hash":"2548bd6ce44422edc7e6f9f68061ab47f26c4f57","modified":1681632350148},{"_id":"themes/cactus/README.md","hash":"778ff0b9caf666d2c0dc3413e26ffb862f354173","modified":1681632350149},{"_id":"themes/cactus/gulpfile.js","hash":"3f073baa3d9ed36725e518606de61bcc317ad207","modified":1681632350150},{"_id":"themes/cactus/_config.yml","hash":"3990f94de19b53cb3d0462557ca192010e4da4b1","modified":1686989931912},{"_id":"themes/cactus/LICENSE","hash":"346ece39a983b0e7858c11f785cd846cef9eb875","modified":1681632350149},{"_id":"themes/cactus/languages/ca.yml","hash":"b79dd2c21dc6697c635e92db1f661a4b8d5d2305","modified":1681632350150},{"_id":"themes/cactus/languages/de.yml","hash":"43b2f4e078b042aaae0377a4235216a51ed82e0d","modified":1681632350150},{"_id":"themes/cactus/package.json","hash":"0eddf80e60a40d107585f7a8a512f7785cda8163","modified":1681632350160},{"_id":"themes/cactus/languages/default.yml","hash":"6a84970bf69c3e9490e5382747ca2b4c4b4dccde","modified":1681632350151},{"_id":"themes/cactus/languages/ar.yml","hash":"81a88b0593fc89de3118d686681b1f69883c847b","modified":1681632350150},{"_id":"themes/cactus/languages/es.yml","hash":"2b1fc8b0d636123e9ee39017fa20053bd1913a5a","modified":1681632350151},{"_id":"themes/cactus/languages/en.yml","hash":"6a84970bf69c3e9490e5382747ca2b4c4b4dccde","modified":1681632350151},{"_id":"themes/cactus/languages/fr.yml","hash":"5c07406998f19d219a5a7b65c0d88b6b023f85b2","modified":1681632350152},{"_id":"themes/cactus/languages/fa.yml","hash":"63f32e50953af1c4bd0308a4fca5862b5287c2cb","modified":1681632350152},{"_id":"themes/cactus/languages/nl.yml","hash":"ac0573352ad2c737a7686bcca498b985e7bd6447","modified":1681632350153},{"_id":"themes/cactus/languages/it.yml","hash":"62800bcae1f2d2454f87f4bcf4d7593848424f61","modified":1681632350152},{"_id":"themes/cactus/languages/pl.yml","hash":"8a2d6dc874d86c38d42c2c861c39590647b5d536","modified":1681632350153},{"_id":"themes/cactus/languages/vi.yml","hash":"f84893c3ec3e45875c90069e14b17ed3016ed973","modified":1681632350154},{"_id":"themes/cactus/languages/kr.yml","hash":"651fb83991c91b13b53ed55740e5402cf0f1c5e8","modified":1681632350152},{"_id":"themes/cactus/languages/pt-br.yml","hash":"4859aba788a050c2d5d0b997693b0c8c24b349f7","modified":1681632350153},{"_id":"themes/cactus/languages/tr.yml","hash":"2702914007e6bade9d6861078c0e179ac05bf48c","modified":1681632350153},{"_id":"themes/cactus/languages/zh-CN.yml","hash":"d016060817311addb4c528de440126b975038c31","modified":1681632350154},{"_id":"themes/cactus/languages/ru.yml","hash":"81b57fcd1977ef534f4bf303dbc1b4710cc7f057","modified":1681632350153},{"_id":"themes/cactus/layout/404.ejs","hash":"b911da998c160cceb8cd7c4dae709a1374ed2491","modified":1681632350155},{"_id":"themes/cactus/languages/zh-TW.yml","hash":"2f4e050c9b35a67f4a7278cec3a949533c2ac16a","modified":1681632350154},{"_id":"themes/cactus/layout/archive.ejs","hash":"5a23d506dd65f9b5fd1d44a73d5e04c935a899e2","modified":1681632350159},{"_id":"themes/cactus/layout/page.ejs","hash":"c5465d5315a7544aa466b01fd8cfb62917a8bb1d","modified":1681632350160},{"_id":"themes/cactus/layout/layout.ejs","hash":"8504004f2ed78914f806c6699d9bd722318cbe56","modified":1681632350160},{"_id":"themes/cactus/layout/post.ejs","hash":"f9149f294e6142437c58784c41f1d082a61c8b82","modified":1681632350160},{"_id":"themes/cactus/scripts/meta.js","hash":"654868666b6573b2cee7e750b47ad8a3c2ee13a0","modified":1681632350161},{"_id":"themes/cactus/scripts/error_404.js","hash":"f83b290e47cb78a2754152fccc34e571a72087bd","modified":1681632350161},{"_id":"themes/cactus/scripts/cdn.js","hash":"887edec364d51efa7c524446483188c6ad05adaf","modified":1681632350161},{"_id":"themes/cactus/scripts/merge-configs.js","hash":"2048c3415d96b17b9d84aa44bc0c25f1210525f8","modified":1681632350161},{"_id":"themes/cactus/scripts/page_title.js","hash":"fa662dbdb82779af1b95e35ed7ccdf4866a53dee","modified":1681632350162},{"_id":"themes/cactus/scripts/thumbnail.js","hash":"df8829fd8c3119650037eba5ec11bdce06acff9d","modified":1681632350162},{"_id":"themes/cactus/layout/_partial/comments.ejs","hash":"4e75035a427fd137ae7f12940209e8e97845df3b","modified":1681632350155},{"_id":"themes/cactus/layout/_partial/footer.ejs","hash":"12fd63b51472c9c5b8b7d167eb1a96bf1d686c20","modified":1681632350155},{"_id":"themes/cactus/layout/_partial/header.ejs","hash":"0e06ee826de1af22a63626456ceb8f2b6c0d1555","modified":1681632350156},{"_id":"themes/cactus/layout/_partial/head.ejs","hash":"95526bec071998144ee0b0fc33f39bb74e5e9c4f","modified":1681632350156},{"_id":"themes/cactus/layout/index.ejs","hash":"0b880a0f497ea597bf5213b4210c852508a5d559","modified":1681632350159},{"_id":"themes/cactus/layout/_partial/pagination.ejs","hash":"23bf862b3b8a3cd831850504d9b5a24d21b005e7","modified":1681632350156},{"_id":"themes/cactus/layout/_partial/scripts.ejs","hash":"a901e3c89e4cd1d20a87bfc683b64b6818275946","modified":1681632350159},{"_id":"themes/cactus/layout/_partial/styles.ejs","hash":"c6bc7e8a422c5bb57f88fed1d1b0694d03e24e74","modified":1681632350159},{"_id":"themes/cactus/layout/_partial/search.ejs","hash":"8b4bf9cf5db0ce762a31fc3baae0f2fc004bece4","modified":1681632350159},{"_id":"themes/cactus/source/css/_fonts.styl","hash":"354809b5a64e8a47a66c66fd1a28ac597c1460a6","modified":1681632350164},{"_id":"themes/cactus/source/css/_variables.styl","hash":"69d9c5e95edcaee5ccd8218262b989ce721cce79","modified":1681632350184},{"_id":"themes/cactus/source/css/_util.styl","hash":"2bfeb2e2605dd5235693b00c71a212646d2e0410","modified":1681632350183},{"_id":"themes/cactus/source/css/rtl.styl","hash":"ff8700e1626feeb53d905a2df2777bda7d1eca50","modified":1681632350184},{"_id":"themes/cactus/source/css/style.styl","hash":"17b427bd19ee9d00efc6f71dcaa00b1fa2df6e70","modified":1681632350184},{"_id":"themes/cactus/source/images/apple-touch-icon.png","hash":"57e2def34682655f41a0be2d083f16765ba7858b","modified":1681632350185},{"_id":"themes/cactus/source/css/_extend.styl","hash":"b6a4e5905a7515dda66919167531a5ab2b3d1fe2","modified":1681632350163},{"_id":"themes/cactus/source/css/_mixins.styl","hash":"1a9e309523df9685e8d088dcff0a809c58e2c392","modified":1681632350180},{"_id":"themes/cactus/source/.DS_Store","hash":"553149ba02a6f33a87f0203809f9578629a5f6fa","modified":1681686565998},{"_id":"themes/cactus/source/images/gpu.png","hash":"da5dc3451fe333b270366b0619ed3a1e52910913","modified":1681632350185},{"_id":"themes/cactus/source/images/favicon-192x192.png","hash":"89580c4f5502c83b7fbfcad1a9841a0998993a43","modified":1681632350186},{"_id":"themes/cactus/source/images/gpu_logo.png","hash":"89580c4f5502c83b7fbfcad1a9841a0998993a43","modified":1681632350186},{"_id":"themes/cactus/source/js/main.js","hash":"619ac6529d140711e3b14f739a192bb31c4824ff","modified":1681632350187},{"_id":"themes/cactus/source/images/.DS_Store","hash":"ab8ed90fde1e6d092daf3f98d0624733099cb18d","modified":1681632631454},{"_id":"themes/cactus/source/images/favicon.ico","hash":"d547f35d7e78c5d7109ffed6e1eec5e6c5ccb2f1","modified":1681632548215},{"_id":"themes/cactus/layout/_partial/post/actions_mobile.ejs","hash":"79b234ff3c264e66b2e71c819228e62bf92b48e4","modified":1681632350157},{"_id":"themes/cactus/layout/_partial/post/actions_desktop.ejs","hash":"aa6218d8d5af1e26e7a0d805b1ea864eca2b88c5","modified":1681632350157},{"_id":"themes/cactus/source/js/search.js","hash":"914a2ce72fb325106c61600200be823b72bfb39f","modified":1681632350187},{"_id":"themes/cactus/layout/_partial/post/category.ejs","hash":"b5bfa049f17868fb09d9d2a7e1d5279fa0381d37","modified":1681632350157},{"_id":"themes/cactus/layout/_partial/post/date.ejs","hash":"6f2d1aa9562df343b797d25705f1945323c465fb","modified":1681632350157},{"_id":"themes/cactus/layout/_partial/post/tag.ejs","hash":"e08fae30da060f49c087f6c121868b08eb55c795","modified":1681632350158},{"_id":"themes/cactus/layout/_partial/post/share.ejs","hash":"1a294382bd14d979525b8ed934d807bc7d083e4d","modified":1681632350158},{"_id":"themes/cactus/layout/_partial/post/gallery.ejs","hash":"9aecd8908e8a684f33dc20c02497c0f1774137c7","modified":1681632350158},{"_id":"themes/cactus/layout/_partial/post/title.ejs","hash":"a060f1c6e3718494a6b1d0e1981ea0bf4e549828","modified":1681632350158},{"_id":"themes/cactus/source/css/_colors/dark.styl","hash":"9aa43b1f23d5d268dfa36bd942d6ce97b7677c4d","modified":1681632350163},{"_id":"themes/cactus/source/css/_colors/classic.styl","hash":"bc09f8777a6c99030da953dfdb84f793c5e4fd85","modified":1681632350163},{"_id":"themes/cactus/source/css/_colors/light.styl","hash":"d14ef1aa02d0895b6f9321ebfc23a1ec84b054b8","modified":1681632350163},{"_id":"themes/cactus/source/css/_colors/white.styl","hash":"88e93a9d3fe1d0270d65cabdeacc18bd94d45937","modified":1681632350163},{"_id":"themes/cactus/source/css/_partial/article.styl","hash":"258370d8ab98e63804ead9bc030f633ca97a1235","modified":1681632350181},{"_id":"themes/cactus/source/css/_partial/categories.styl","hash":"a43f00e61b3507f130b8a3f8108a4eeca147c2a0","modified":1681632350181},{"_id":"themes/cactus/source/css/_partial/archive.styl","hash":"31aef892437d5734a134c34f2a8a6610a8f671c3","modified":1681632350181},{"_id":"themes/cactus/source/css/_partial/comments.styl","hash":"1e90f1fb9d4c155df518cacb5a537e9de9c042c1","modified":1681632350181},{"_id":"themes/cactus/source/css/_partial/footer.styl","hash":"61c2c7c5f73a0022ec41830bea0812a97f522d7c","modified":1681632350181},{"_id":"themes/cactus/source/css/_partial/index.styl","hash":"59c99f4ea3a73bf47ce030df166c5e33d5de31fb","modified":1681632350182},{"_id":"themes/cactus/source/css/_partial/pagination.styl","hash":"950bf517bbe7adb9a9aa4eb5ddec74ffc7598787","modified":1681632350182},{"_id":"themes/cactus/source/css/_partial/tags.styl","hash":"d571d5c7c960300d29c5f0ec3fe1140322ecd6b3","modified":1681632350183},{"_id":"themes/cactus/source/css/_partial/tooltip.styl","hash":"2daff581ec3efaec840cbfdee512195919c32629","modified":1681632350183},{"_id":"themes/cactus/source/css/_highlight/androidstudio.styl","hash":"2af0861725f97f0ee2ded67c3d2d4548c62b2d16","modified":1681632350164},{"_id":"themes/cactus/source/css/_partial/header.styl","hash":"7f18929e7f4ad6d20da374e8b9f85ce587220a87","modified":1681632350182},{"_id":"themes/cactus/source/css/_partial/search.styl","hash":"159be002780c62a77f46947cf854a7342fba24f4","modified":1681632350183},{"_id":"themes/cactus/source/css/_highlight/agate.styl","hash":"53027913ed8d4f75ac3e49e76aad824f0df62da3","modified":1681632350164},{"_id":"themes/cactus/source/css/_highlight/arduino-light.styl","hash":"15e8572585cd708221c513dea4bdd89d8fe56c10","modified":1681632350165},{"_id":"themes/cactus/source/css/_highlight/ascetic.styl","hash":"32cff3bef6fac3760fe78f203096477052a90552","modified":1681632350165},{"_id":"themes/cactus/source/css/_highlight/atelier-cave-dark.styl","hash":"ce63dd8548688d88254405eedfa75b1d7c82449e","modified":1681632350165},{"_id":"themes/cactus/source/css/_highlight/atelier-cave-light.styl","hash":"a5be0744a7ecf4a08f600ade4cfd555afc67bc15","modified":1681632350165},{"_id":"themes/cactus/source/css/_highlight/atelier-dune-dark.styl","hash":"c196ff0ee064af0e507823694ae39020addfc280","modified":1681632350166},{"_id":"themes/cactus/source/css/_highlight/arta.styl","hash":"b3e81e3e694ceb8deed178adb8b91013c5120e30","modified":1681632350165},{"_id":"themes/cactus/source/css/_highlight/atelier-estuary-dark.styl","hash":"0bb16a4eff93688f40787abc2f9e56e7d5cc93e7","modified":1681632350166},{"_id":"themes/cactus/source/css/_highlight/atelier-estuary-light.styl","hash":"344276ca9b27e51d4c907f76afe5d13cf8e60bdf","modified":1681632350166},{"_id":"themes/cactus/source/css/_highlight/atelier-dune-light.styl","hash":"931435fbc6f974e8ce9e32722680035d248a9dc1","modified":1681632350166},{"_id":"themes/cactus/source/css/_highlight/atelier-forest-light.styl","hash":"95228d9f2102fad425536aac44b80b2cba1f5950","modified":1681632350167},{"_id":"themes/cactus/source/css/_highlight/atelier-heath-light.styl","hash":"8c8c2e445abef85273be966d59770e9ced6aac21","modified":1681632350167},{"_id":"themes/cactus/source/css/_highlight/atelier-forest-dark.styl","hash":"effbc5d75fa87203c847039869c22031b40d5b7d","modified":1681632350167},{"_id":"themes/cactus/source/css/_highlight/atelier-heath-dark.styl","hash":"9a2e9a1d0a01bbdf158560c3ed1c134e098b2c68","modified":1681632350167},{"_id":"themes/cactus/source/css/_highlight/atelier-lakeside-dark.styl","hash":"10ee3882fca7b97a37bd309d2d35fce9868647bb","modified":1681632350167},{"_id":"themes/cactus/source/css/_highlight/atelier-lakeside-light.styl","hash":"2c54cb9bdb259ae3b5b29f63ac2469ed34b08578","modified":1681632350168},{"_id":"themes/cactus/source/css/_highlight/atelier-plateau-light.styl","hash":"d1a05fdd1ededc9063d181ab25bad55a164aeb4a","modified":1681632350168},{"_id":"themes/cactus/source/css/_highlight/atelier-plateau-dark.styl","hash":"84c80e6f67f62fce958d25817c277d2360272617","modified":1681632350168},{"_id":"themes/cactus/source/css/_highlight/atelier-savanna-dark.styl","hash":"e32c1c70def8060fce5e790979a126da650ac642","modified":1681632350169},{"_id":"themes/cactus/source/css/_highlight/atelier-seaside-light.styl","hash":"0597342da6e2d0c5bdcc7d42dabb07322b1a4177","modified":1681632350169},{"_id":"themes/cactus/source/css/_highlight/atelier-seaside-dark.styl","hash":"2edf385215bbe1985b1a10106525d362667d28c2","modified":1681632350169},{"_id":"themes/cactus/source/css/_highlight/atelier-sulphurpool-dark.styl","hash":"538a14321193cd8abf2ddc484306631e54149ffb","modified":1681632350169},{"_id":"themes/cactus/source/css/_highlight/atelier-savanna-light.styl","hash":"f8244c93711c7cb59dd79d2df966806b30d171ea","modified":1681632350169},{"_id":"themes/cactus/source/css/_highlight/atelier-sulphurpool-light.styl","hash":"efa52713efc468abeeb2b9299704371583b857de","modified":1681632350170},{"_id":"themes/cactus/source/css/_highlight/brown-paper.styl","hash":"c2326ba20a5020a66ca7895258d18833327d4334","modified":1681632350170},{"_id":"themes/cactus/source/css/_highlight/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1681632350170},{"_id":"themes/cactus/source/css/_highlight/color-brewer.styl","hash":"2a439d6214430e2f45dd4939b4dfe1fe1a20aa0f","modified":1681632350171},{"_id":"themes/cactus/source/css/_highlight/dark.styl","hash":"f5e6e75958de59e87fc6be3a1668e870e20bc836","modified":1681632350171},{"_id":"themes/cactus/source/css/_highlight/codepen-embed.styl","hash":"8b7b34484f76a6c2c3b1a9e49abb9b382f439ae8","modified":1681632350170},{"_id":"themes/cactus/source/css/_highlight/far.styl","hash":"aaac3028f5e33123cd123a583cddc9290c45ec8e","modified":1681632350171},{"_id":"themes/cactus/source/css/_highlight/docco.styl","hash":"b1c176378bb275f2e8caa759f36294e42d614bf1","modified":1681632350171},{"_id":"themes/cactus/source/css/_highlight/foundation.styl","hash":"bf8ddc94b4ad995b8b8805b5a4cf95004553fdac","modified":1681632350172},{"_id":"themes/cactus/source/css/_highlight/darkula.styl","hash":"9717efa9194837ba3fb4d762997d33075dcf8bfa","modified":1681632350171},{"_id":"themes/cactus/source/css/_highlight/github-gist.styl","hash":"48211a03d33e7f7ada0b261162bea06676155a71","modified":1681632350172},{"_id":"themes/cactus/source/css/_highlight/github.styl","hash":"3336aeba324c6d34a6fd41fef9b47bc598f7064c","modified":1681632350172},{"_id":"themes/cactus/source/css/_highlight/gruvbox-dark.styl","hash":"76b744c14fd5600bea64731c05df97c2df75523f","modified":1681632350173},{"_id":"themes/cactus/source/css/_highlight/googlecode.styl","hash":"bda816beee7b439814b514e6869dc678822be1bc","modified":1681632350172},{"_id":"themes/cactus/source/css/_highlight/grayscale.styl","hash":"bf37d8b8d1e602126c51526f0cc28807440228ed","modified":1681632350173},{"_id":"themes/cactus/source/css/_highlight/hopscotch.styl","hash":"1378a6bc67a32c0cbff72ab771268b53f9aa586d","modified":1681632350173},{"_id":"themes/cactus/source/css/_highlight/hybrid.styl","hash":"b8eb5c69d12f2ee5ebc50265ae271699d7f1a8d3","modified":1681632350173},{"_id":"themes/cactus/source/css/_highlight/idea.styl","hash":"a02967cb51c16a34e0ee895d33ded2b823d35b21","modified":1681632350174},{"_id":"themes/cactus/source/css/_highlight/ir-black.styl","hash":"53e5d74326a4527b92272bbd6946d4fec92720e8","modified":1681632350174},{"_id":"themes/cactus/source/css/_highlight/kimbie.dark.styl","hash":"45dbb168f22d739d0109745d2decd66b5f94e786","modified":1681632350174},{"_id":"themes/cactus/source/css/_highlight/index.styl","hash":"002d5596f6379cc87dbd43d9145bc764aa666be1","modified":1681632350174},{"_id":"themes/cactus/source/css/_highlight/kimbie.light.styl","hash":"61f8baed25be05288c8604d5070afbcd9f183f49","modified":1681632350174},{"_id":"themes/cactus/source/css/_highlight/highlightjs.styl","hash":"0e198b7a59191c7a39b641a4ddd22c948edb9358","modified":1681632350173},{"_id":"themes/cactus/source/css/_highlight/mono-blue.styl","hash":"4c89a6ae29de67c0700585af82a60607e85df928","modified":1681632350175},{"_id":"themes/cactus/source/css/_highlight/magula.styl","hash":"16d323f989b1420a0f72ef989242ece9bf17a456","modified":1681632350175},{"_id":"themes/cactus/source/css/_highlight/monokai-sublime.styl","hash":"c385b11345894be7e6ce3c5f08663e199933b8e4","modified":1681632350175},{"_id":"themes/cactus/source/css/_highlight/paraiso-dark.styl","hash":"f1537bd868579fa018ecdbfd2eb922dcf3ba2cac","modified":1681632350176},{"_id":"themes/cactus/source/css/_highlight/paraiso-light.styl","hash":"d224d1df0eb3395d9eea1344cee945c228af2911","modified":1681632350176},{"_id":"themes/cactus/source/css/_highlight/kimbie.styl","hash":"51b889ca7c6fe178cfbbe28d875a6ea427184441","modified":1681632350175},{"_id":"themes/cactus/source/css/_highlight/paraiso.styl","hash":"75f181eece6b71d033ea0c8d6cf00ae7efb9e29b","modified":1681632350176},{"_id":"themes/cactus/source/css/_highlight/monokai.styl","hash":"f87be027848ea6bee623a08ad1e17b2f5b7937ee","modified":1681632350176},{"_id":"themes/cactus/source/css/_highlight/pojoaque.jpg","hash":"c5fe6533b88b21f8d90d3d03954c6b29baa67791","modified":1681632350177},{"_id":"themes/cactus/source/css/_highlight/obsidian.styl","hash":"199e28326be8590883f0813ebbd54fcfaa4750fd","modified":1681632350176},{"_id":"themes/cactus/source/css/_highlight/rainbow.styl","hash":"c0cf97aae3e10fdcd10414547a711c9effbc39b8","modified":1681632350177},{"_id":"themes/cactus/source/css/_highlight/pojoaque.styl","hash":"4e7b6b046b8575ac749f6aec4e953a62ada27a36","modified":1681632350177},{"_id":"themes/cactus/source/css/_highlight/solarized-light.styl","hash":"aa0dd3fd25c464183b59c5575c9bee8756b397f2","modified":1681632350178},{"_id":"themes/cactus/source/css/_highlight/railscasts.styl","hash":"b6674db9210e0c4444e4835fff2d1361f3ebd64c","modified":1681632350177},{"_id":"themes/cactus/source/css/_highlight/solarized-dark.styl","hash":"90c9da5aa594383697e5b18892a7f95beb053f55","modified":1681632350178},{"_id":"themes/cactus/source/css/_highlight/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1681632350177},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night-blue.styl","hash":"f24c17d0ab815dcfaab3438cb9fe2ab4839f5e0d","modified":1681632350179},{"_id":"themes/cactus/source/css/_highlight/sunburst.styl","hash":"af3eec0fd56151e55bbd49c31b151f36717611d8","modified":1681632350178},{"_id":"themes/cactus/source/css/_highlight/school-book.styl","hash":"d43560fe519a931ce6da7d57416d7aa148441b83","modified":1681632350178},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night.styl","hash":"16ba09b2db501e4e3e2e7d62595d9bf935bf27c4","modified":1681632350179},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night-eighties.styl","hash":"28d751075ebabf7d0327a36f725076fe82fdf626","modified":1681632350179},{"_id":"themes/cactus/source/css/_highlight/tomorrow.styl","hash":"15779cf6846725c7c35fc56cac39047d7e0aec1c","modified":1681632350179},{"_id":"themes/cactus/source/css/_highlight/tomorrow-night-bright.styl","hash":"7674fecb6d27350727dc0d2dc93bc018382ebbd0","modified":1681632350179},{"_id":"themes/cactus/source/css/_highlight/vs.styl","hash":"959a746f4b37aacb5d1d6ff1d57e0c045289d75d","modified":1681632350180},{"_id":"themes/cactus/source/css/_highlight/xcode.styl","hash":"5e8532ae8366dcf6a4ef5e4813dc3d42ab3d0a50","modified":1681632350180},{"_id":"themes/cactus/source/css/_highlight/zenburn.styl","hash":"68ff9332ccc03f9389b15b713415cde016f8088f","modified":1681632350180},{"_id":"themes/cactus/source/lib/clipboard/clipboard.min.js","hash":"6674f81dd01c76be986cf0a8172d1073e56d7ef4","modified":1681632350187},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff","hash":"f6fda2de0348b3e3b7de73267f9f8e97a62f8353","modified":1681632350217},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.woff2","hash":"7ea4fd7dd4cd4f480af78a0e2c5849eb921b1aeb","modified":1681632350218},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff","hash":"56e632c9196fac364c66f812a3b4635dd999ad1c","modified":1681632350219},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.woff2","hash":"6e40d0c7669c1adbcbf034bdc459f7bed4d6676d","modified":1681632350219},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff","hash":"1c3dbf17411b1f6a6b22c2b76e9d8511586643d0","modified":1681632350221},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.woff2","hash":"50b654d916204c30987d1987abd890ef92085ae3","modified":1681632350221},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff2","hash":"14b3e257c51a6a11d23b2a078017ff340c9777e4","modified":1681632350226},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.woff","hash":"43a8aaa3fca8721dd32a5d20f7a98dfbc87c97fd","modified":1681632350225},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.woff","hash":"235889d59ddad2b1f3243ccaab7733bd713a2a21","modified":1681632350227},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.woff2","hash":"a9714ffb842afc74836e64de04b52d8c37c87c8a","modified":1681632350227},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff2","hash":"9b03b1a9071709f5b7dbca13412ecef6cb7a2a67","modified":1681632350229},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.woff","hash":"c0e784de2eb5261cca244928f8a81fd893c3fe16","modified":1681632350229},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.woff2","hash":"e213bb26bc7f10e1df3fe2d03d3ecaecd6e6d371","modified":1681632350230},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.woff","hash":"2e8e6d38d361def5f48baac366f04e3db3ed4828","modified":1681632350230},{"_id":"themes/cactus/source/css/_partial/post/actions_desktop.styl","hash":"a1f36f9a3fd5ffcd832bf39e9402678978035d48","modified":1681632350182},{"_id":"themes/cactus/source/css/_partial/post/actions_mobile.styl","hash":"0d2966c1d870392476864af8ee3ba312ba30cb82","modified":1681632350182},{"_id":"themes/cactus/source/lib/vazir-font/font-face.css","hash":"ba0030e1cd28a8caa7a5bb74b98da7c7bb185c90","modified":1681632350231},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"be22b700cc80c242da898ef8b7bb96adc4e0899f","modified":1681632350190},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-regular-400.ttf","hash":"d1a7eff18db8a47207ea42e34e9d9fbcc66a97a7","modified":1681632350190},{"_id":"themes/cactus/source/lib/justified-gallery/css/justifiedGallery.min.css","hash":"dd3052149d3054f35efb823c68dd78e78aad5875","modified":1681632350193},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-v4compatibility.ttf","hash":"c77fcea87e0c4953f2b0ac92dc49a31c664b6ef7","modified":1681632350192},{"_id":"themes/cactus/source/lib/justified-gallery/js/jquery.justifiedGallery.min.js","hash":"ad8f48b4022498078b089fcdd1e8b47faf496931","modified":1681632350193},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-v4compatibility.woff2","hash":"60d794c18c2b58b2b76d2ce17b85c44c48fb2efd","modified":1681632350192},{"_id":"themes/cactus/source/lib/jquery/jquery.min.js","hash":"b82d238d4e31fdf618bae8ac11a6c812c03dd0d4","modified":1681632350192},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.eot","hash":"91152bd73e7ff8d943e3bde3ddb0fa0a018e1c21","modified":1681632350216},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Black.ttf","hash":"b65915e3fa57b5c19995d15dc2341d115c1971b9","modified":1681632350217},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.eot","hash":"5c1c680fade45393e4a5bb4548a092cd5ea6811e","modified":1681632350218},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Bold.ttf","hash":"122bb778b17a152c426a825ee981610a4bd59bf3","modified":1681632350218},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.eot","hash":"a059359e9bea17dc2ff2ede955a05bf0dc4d00d0","modified":1681632350220},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Light.ttf","hash":"df82b80c4d3b11e70dcd269fc62ac97cbfa0414d","modified":1681632350220},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.eot","hash":"d9ec1f9f3fefd57e446cbe86dc297f1ff269b6de","modified":1681632350221},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Medium.ttf","hash":"948a091f0fdb8c7ae17d5ef8e51bd8830d65dd9a","modified":1681632350222},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.eot","hash":"521c01f0eb79a48025e972ecbe21b0d7fb15437b","modified":1681632350226},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Regular.ttf","hash":"643c28c8f8a2bce1a0d62525aa045cd9883773cd","modified":1681632350226},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.ttf","hash":"6aacb0eecb03c660570b6e159ba5ca97ca7461cf","modified":1681632350228},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Thin.eot","hash":"a0ea0bdaef00b35544f9a21d25d35db9a79f7189","modified":1681632350228},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.ttf","hash":"1e08b6373c2e086f24776df9b11e4be6bbcc8a4a","modified":1681632350230},{"_id":"themes/cactus/source/lib/font-awesome/css/all.min.css","hash":"d3cafed4c6596253c1050ee63897aa0f440e4f65","modified":1681632350188},{"_id":"themes/cactus/source/lib/vazir-font/Vazir-Variable.eot","hash":"af46f7f4e10a1440a4c97b350622d279143e6798","modified":1681632350229},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"98564e5517b7b455e80b2cd503e7bb3b52beb930","modified":1681632350189},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-brands-400.ttf","hash":"cfb2c6122bd53141e939ee4ff991a16a29d1bdce","modified":1681632350189},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"09a731f80844483614ff12f86ccbe41db6736cb5","modified":1681632350191},{"_id":"themes/cactus/source/images/logo.png","hash":"0e3029251dfda26adee2761f71377297e8c26871","modified":1681632350186},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-BoldItalic.ttf","hash":"b7d24ab1e4fad720f31a2b0cca1904ce1740d846","modified":1681632350199},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-BoldItalic.ttf","hash":"b542b9591fbf33925d93f0695b6e123a9f0cfd43","modified":1681632350206},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-BoldItalic.ttf","hash":"926035f0156cccf1b0ca507347f39bf9c510f51e","modified":1681632350213},{"_id":"themes/cactus/source/lib/font-awesome/webfonts/fa-solid-900.ttf","hash":"97f5404656d9547666479ec64c336467000656ef","modified":1681632350191},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Italic.ttf","hash":"9a23c6898b0943bd3d96c04df9a0f66e919451d8","modified":1681632350201},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Italic.ttf","hash":"93ebc5098cf57a32b7b8d297681f31692c09bdfa","modified":1681632350207},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Italic.ttf","hash":"9d757cc9f928fc83b2133283dd639c12b11d94ad","modified":1681632350214},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Bold.ttf","hash":"34f7db59f1d023294e69976aa20b7d52b86165a4","modified":1681632350194},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGL-Regular.ttf","hash":"6c090d6bff3928fbf8a5f4104e58ed7f421aea7c","modified":1681632350203},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Bold.ttf","hash":"f9918fb93d6ab6850f5d38069a999c311af78816","modified":1681632350212},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Bold.ttf","hash":"58be4b7760e9a84daa81929d046f9a15c4fd1c1a","modified":1681632350204},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGM-Regular.ttf","hash":"20ce1fc7ae1254558ca044ae48283faaa58897e5","modified":1681632350208},{"_id":"themes/cactus/source/lib/meslo-LG/MesloLGS-Regular.ttf","hash":"de559f8d70d5b1ab2810597bfd0b1b9506f3ef01","modified":1681632350215},{"_id":"public/about/index.html","hash":"ba8863cfc7eac1fe3bcd7a24697d4fbb795a5500","modified":1682403245364},{"_id":"public/search/index.html","hash":"70921dc281726fc7af2fa08991978a74b43ac5df","modified":1682403245364},{"_id":"public/tags/index.html","hash":"e05b8aca7c07644a4b130e31fe31166cede08b3c","modified":1682403245364},{"_id":"public/tags/x86/index.html","hash":"effd551d6669b7bb66448aac0b2f709f885e4b01","modified":1682403245364},{"_id":"public/tags/Compiler/index.html","hash":"bddbfedf33b13a8c9f49138ba5ec3f330da2327c","modified":1682403245364},{"_id":"public/tags/Intel/index.html","hash":"b2a2b30c98f6dab028f79d807fca47d788635041","modified":1682403245364},{"_id":"public/tags/NET-Core/index.html","hash":"d07c8a812bbf57e3cd16614faf5a529293756247","modified":1682403245364},{"_id":"public/tags/SIMD/index.html","hash":"993812ebd8b8801db6f3471733edb255bbb977f0","modified":1682403245364},{"_id":"public/archives/index.html","hash":"43a09b6ec2271b4b3722618e4e9fa81d9ef6b747","modified":1682403245364},{"_id":"public/archives/2019/index.html","hash":"608473be0d56ab70b9e0919615bb37654c320963","modified":1682403245364},{"_id":"public/archives/2019/03/index.html","hash":"5eb267db0e3e0d5ad3b7a442c3585bf56962c755","modified":1682403245364},{"_id":"public/archives/2020/index.html","hash":"6a8d066d029242a995f6c5cce105eefb067b8c64","modified":1682403245364},{"_id":"public/archives/2020/02/index.html","hash":"c96aa03ce072cbc0d6c4a97466a892e014011014","modified":1682403245364},{"_id":"public/index.html","hash":"dded3cb1c084d1668948acf7b44b01d547327f5c","modified":1686989951894},{"_id":"public/404.html","hash":"f5ab80908633a2438be26e7df63d8ee5a1b18acc","modified":1682403245364},{"_id":"public/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/index.html","hash":"38b1015ef5896b14d06b6f61ea98c67aa1686578","modified":1682403245364},{"_id":"public/2019/03/03/Hardware-intrinsic-in-NET-Core-3-0-Introduction/index.html","hash":"7332d6f03caa5d20d06d7ab967d79db844888cca","modified":1682403245364},{"_id":"public/CNAME","hash":"c9fe4285ce0728b0a1cb389b9bf4e3a5632b141e","modified":1681633079165},{"_id":"public/images/favicon.ico","hash":"d547f35d7e78c5d7109ffed6e1eec5e6c5ccb2f1","modified":1681633079165},{"_id":"public/images/apple-touch-icon.png","hash":"57e2def34682655f41a0be2d083f16765ba7858b","modified":1681633079165},{"_id":"public/images/gpu.png","hash":"da5dc3451fe333b270366b0619ed3a1e52910913","modified":1681633079165},{"_id":"public/images/favicon-192x192.png","hash":"89580c4f5502c83b7fbfcad1a9841a0998993a43","modified":1681633079165},{"_id":"public/images/gpu_logo.png","hash":"89580c4f5502c83b7fbfcad1a9841a0998993a43","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Black.woff","hash":"f6fda2de0348b3e3b7de73267f9f8e97a62f8353","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Black.woff2","hash":"7ea4fd7dd4cd4f480af78a0e2c5849eb921b1aeb","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Bold.woff2","hash":"6e40d0c7669c1adbcbf034bdc459f7bed4d6676d","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Light.woff","hash":"1c3dbf17411b1f6a6b22c2b76e9d8511586643d0","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Bold.woff","hash":"56e632c9196fac364c66f812a3b4635dd999ad1c","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Light.woff2","hash":"50b654d916204c30987d1987abd890ef92085ae3","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Regular.woff","hash":"235889d59ddad2b1f3243ccaab7733bd713a2a21","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Medium.woff","hash":"43a8aaa3fca8721dd32a5d20f7a98dfbc87c97fd","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Medium.woff2","hash":"14b3e257c51a6a11d23b2a078017ff340c9777e4","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Regular.woff2","hash":"a9714ffb842afc74836e64de04b52d8c37c87c8a","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Thin.woff2","hash":"9b03b1a9071709f5b7dbca13412ecef6cb7a2a67","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Thin.woff","hash":"c0e784de2eb5261cca244928f8a81fd893c3fe16","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Variable.woff","hash":"2e8e6d38d361def5f48baac366f04e3db3ed4828","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.woff2","hash":"be22b700cc80c242da898ef8b7bb96adc4e0899f","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Variable.woff2","hash":"e213bb26bc7f10e1df3fe2d03d3ecaecd6e6d371","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-regular-400.ttf","hash":"d1a7eff18db8a47207ea42e34e9d9fbcc66a97a7","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-v4compatibility.ttf","hash":"c77fcea87e0c4953f2b0ac92dc49a31c664b6ef7","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-v4compatibility.woff2","hash":"60d794c18c2b58b2b76d2ce17b85c44c48fb2efd","modified":1681633079165},{"_id":"public/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/ADD.png","hash":"25116658115939c638feb9cdbc477a721127d75d","modified":1681633079165},{"_id":"public/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS1.png","hash":"de7a657fee2dfcf017b4c16faab0e4a4d8f9402f","modified":1681633079165},{"_id":"public/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS2.png","hash":"46265ff0cbc4fee49e5495abebd078fec597cd1e","modified":1681633079165},{"_id":"public/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS3.png","hash":"81b6002a1b11148df372b653e1820bb0203dd264","modified":1681633079165},{"_id":"public/css/rtl.css","hash":"9589fac02a34fd9084f805f801889028756bbb65","modified":1681633079165},{"_id":"public/js/search.js","hash":"914a2ce72fb325106c61600200be823b72bfb39f","modified":1681633079165},{"_id":"public/js/main.js","hash":"619ac6529d140711e3b14f739a192bb31c4824ff","modified":1681633079165},{"_id":"public/lib/clipboard/clipboard.min.js","hash":"6674f81dd01c76be986cf0a8172d1073e56d7ef4","modified":1681633079165},{"_id":"public/lib/justified-gallery/css/justifiedGallery.min.css","hash":"dd3052149d3054f35efb823c68dd78e78aad5875","modified":1681633079165},{"_id":"public/lib/vazir-font/font-face.css","hash":"ba0030e1cd28a8caa7a5bb74b98da7c7bb185c90","modified":1681633079165},{"_id":"public/css/style.css","hash":"b1b1b9dac588e56e02d457cb271eee6433be83bb","modified":1681633079165},{"_id":"public/lib/jquery/jquery.min.js","hash":"b82d238d4e31fdf618bae8ac11a6c812c03dd0d4","modified":1681633079165},{"_id":"public/lib/font-awesome/css/all.min.css","hash":"d3cafed4c6596253c1050ee63897aa0f440e4f65","modified":1681633079165},{"_id":"public/lib/justified-gallery/js/jquery.justifiedGallery.min.js","hash":"ad8f48b4022498078b089fcdd1e8b47faf496931","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Black.eot","hash":"91152bd73e7ff8d943e3bde3ddb0fa0a018e1c21","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Black.ttf","hash":"b65915e3fa57b5c19995d15dc2341d115c1971b9","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Bold.eot","hash":"5c1c680fade45393e4a5bb4548a092cd5ea6811e","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Bold.ttf","hash":"122bb778b17a152c426a825ee981610a4bd59bf3","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Light.eot","hash":"a059359e9bea17dc2ff2ede955a05bf0dc4d00d0","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Light.ttf","hash":"df82b80c4d3b11e70dcd269fc62ac97cbfa0414d","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Medium.ttf","hash":"948a091f0fdb8c7ae17d5ef8e51bd8830d65dd9a","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Regular.eot","hash":"521c01f0eb79a48025e972ecbe21b0d7fb15437b","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Regular.ttf","hash":"643c28c8f8a2bce1a0d62525aa045cd9883773cd","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Thin.eot","hash":"a0ea0bdaef00b35544f9a21d25d35db9a79f7189","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Medium.eot","hash":"d9ec1f9f3fefd57e446cbe86dc297f1ff269b6de","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Thin.ttf","hash":"6aacb0eecb03c660570b6e159ba5ca97ca7461cf","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Variable.eot","hash":"af46f7f4e10a1440a4c97b350622d279143e6798","modified":1681633079165},{"_id":"public/lib/vazir-font/Vazir-Variable.ttf","hash":"1e08b6373c2e086f24776df9b11e4be6bbcc8a4a","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.woff2","hash":"98564e5517b7b455e80b2cd503e7bb3b52beb930","modified":1681633079165},{"_id":"public/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/LEA.png","hash":"94e4878e215cb6565e68f7dd34ca7edce929fe5f","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-brands-400.ttf","hash":"cfb2c6122bd53141e939ee4ff991a16a29d1bdce","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.woff2","hash":"09a731f80844483614ff12f86ccbe41db6736cb5","modified":1681633079165},{"_id":"public/images/logo.png","hash":"0e3029251dfda26adee2761f71377297e8c26871","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGL-BoldItalic.ttf","hash":"b7d24ab1e4fad720f31a2b0cca1904ce1740d846","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGM-BoldItalic.ttf","hash":"b542b9591fbf33925d93f0695b6e123a9f0cfd43","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGS-BoldItalic.ttf","hash":"926035f0156cccf1b0ca507347f39bf9c510f51e","modified":1681633079165},{"_id":"public/lib/font-awesome/webfonts/fa-solid-900.ttf","hash":"97f5404656d9547666479ec64c336467000656ef","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGL-Italic.ttf","hash":"9a23c6898b0943bd3d96c04df9a0f66e919451d8","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGM-Italic.ttf","hash":"93ebc5098cf57a32b7b8d297681f31692c09bdfa","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGS-Italic.ttf","hash":"9d757cc9f928fc83b2133283dd639c12b11d94ad","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGL-Bold.ttf","hash":"34f7db59f1d023294e69976aa20b7d52b86165a4","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGM-Bold.ttf","hash":"58be4b7760e9a84daa81929d046f9a15c4fd1c1a","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGM-Regular.ttf","hash":"20ce1fc7ae1254558ca044ae48283faaa58897e5","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGL-Regular.ttf","hash":"6c090d6bff3928fbf8a5f4104e58ed7f421aea7c","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGS-Bold.ttf","hash":"f9918fb93d6ab6850f5d38069a999c311af78816","modified":1681633079165},{"_id":"public/lib/meslo-LG/MesloLGS-Regular.ttf","hash":"de559f8d70d5b1ab2810597bfd0b1b9506f3ef01","modified":1681633079165}],"Category":[],"Data":[],"Page":[{"title":"about","date":"2019-03-03T10:35:21.000Z","_content":"\nI am a compiler engineer, currently working on the NVIDIA CUDA compiler and specialize in optimizations. Prior to this, I was employed by Intel, where I collaborated with Microsoft in the development of the .NET Core JIT compiler.\n\n![Parallelize Everything](/images/gpu_logo.png)","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-03-03 02:35:21\n---\n\nI am a compiler engineer, currently working on the NVIDIA CUDA compiler and specialize in optimizations. Prior to this, I was employed by Intel, where I collaborated with Microsoft in the development of the .NET Core JIT compiler.\n\n![Parallelize Everything](/images/gpu_logo.png)","updated":"2023-04-16T08:05:50.136Z","path":"about/index.html","comments":1,"layout":"page","_id":"clgj4x0bp00009tne4tle209a","content":"<p>I am a compiler engineer, currently working on the NVIDIA CUDA compiler and specialize in optimizations. Prior to this, I was employed by Intel, where I collaborated with Microsoft in the development of the .NET Core JIT compiler.</p>\n<p><img src=\"/images/gpu_logo.png\" alt=\"Parallelize Everything\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>I am a compiler engineer, currently working on the NVIDIA CUDA compiler and specialize in optimizations. Prior to this, I was employed by Intel, where I collaborated with Microsoft in the development of the .NET Core JIT compiler.</p>\n<p><img src=\"/images/gpu_logo.png\" alt=\"Parallelize Everything\"></p>\n"},{"title":"search","type":"search","date":"2019-03-04T00:39:10.000Z","_content":"","source":"search/index.md","raw":"---\ntitle: search\ntype: search\ndate: 2019-03-03 16:39:10\n---\n","updated":"2023-04-16T08:05:50.137Z","path":"search/index.html","comments":1,"layout":"page","_id":"clgj4x0bs00029tne00hx6su6","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2019-03-04T09:16:56.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-03-04 01:16:56\ntype: tags\n---\n","updated":"2023-04-16T08:05:50.138Z","path":"tags/index.html","comments":1,"layout":"page","_id":"clgj4x0bu00059tne3m9cfn2q","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Does register selection matter to performance on x86 CPUs?","date":"2020-02-17T02:29:37.000Z","description":["Instruction selection is a critical portion in compilers, as different instructions could cause significant performance differences even though the semantics not changed. Does register selection also matter to performance (assume the register selection does not lead to less or more register spills)? Honestly, I never intentionally thought of this question until I came across it on Zhihu (a Chinese Q&A website). But this is a really interesting topic that reflects many tricks of assembly programming and compiler code generation. So, that deserves a blog to refresh my memory and give a share :)"],"_content":"Instruction selection is a critical portion in compilers, as different instructions could cause significant performance differences even though the semantics not changed. Does register selection also matter to performance (assume the register selection does not lead to less or more register spills)? Honestly, I never intentionally thought of this question until I came across it on Zhihu (a Chinese Q&A website). But this is a really interesting topic that reflects many tricks of assembly programming and compiler code generation. So, that deserves a blog to refresh my memory and give a share :) \n\nIn other words, the question is equivalent to \n> Is one of the instructions below faster than another one?  \n![](Does-register-selection-matter-to-performance-on-x86-CPUs/ADD.png)  \n\nAnd the question can be extended to any instruction of x86/x86-64 ISAs (not only on `ADD`).\n\nFrom undergraduate classes in CS departments, we know modern computer architectures usually have a pipeline stage called __register renaming__ that assigns real physical registers to the named logic register referred to in an assembly instruction. For example, the following code uses `EAX` twice but the two usages are not related to each other.\n```c\nADD EDX, EAX\nADD EAX, EBX\n```\nAssume this code is semantically correct. In practice, CPUs usually assign different physical registers to the two `EAX` for breaking [anti-dependency](https://en.wikipedia.org/wiki/Data_dependency#Anti-dependency). So they can parallel execute on pipelined superscalar CPUs, and `ADD EAX, EBX` does not have to worry about if writing over `EAX` impacts `ADD EDX, EAX`. __Therefore, we usually suppose different register names in assembly code do NOT cause performance difference on modern x86 CPUs.__\n\nIs the story over? No.\n\nThe above statements only hold for general cases. There are a lot of corner cases existing in the real world that our college courses never reached. CPUs are pearls of modern engineering and industry, which also have many corner cases breaking our common sense. So, different register names will impact performance a lot, sometimes. I collected these corner cases in four categories. \n\n> Note, the rest of the article only talks about Intel micro-architectures. \n\n## Special Instructions \nA few instructions are executing slower with certain logic registers due to micro-architecture limitations. The most famous one is `LEA`. \n`LEA` was designed to leverage the complex and powerful x86 addressing-mode in wider areas, such as arithmetic computations, which requires fewer registers for intermediate results than arithmetic instructions. However, certain forms of `LEA` only can be executed on port1, which those `LEA` forms with lower ILP and higher latency are called __slow LEA__. According to the Intel optimization manual, using `EBP`, `RBP`, or `R13` as the base address will make LEA slower.\n  \n![](Does-register-selection-matter-to-performance-on-x86-CPUs/LEA.png)\n\nAlthough compilers could assign other registers to the base address variables, sometimes that is impossible in register allocations and there are more forms of slow LEAs that cannot be improved by register selection. Hence, in general, compilers avoid generating slow LEAs by (1) replacing `LEA` by equivalent instruction sequences that may need more temporary registers or (2) folding `LEA` into its user instructions' addressing modes.\n\n## Partial Register Stall  \nMost kinds of x86 registers (e.g., general-purpose registers, FLAGS, and SIMD registers, etc.) can be accessed by multiple granularities. For instance, `RAX` can be partially accessed via `EAX`, `AX`, `AH`, and `AL`. Accessing `AL` is independent of `AH` on Intel CPUs, but reading `EAX` content that written though `AL` has significant performance degradation (5-6 cycles of latency). Consequently, Intel suggests always using registers with sizes of 32- or 64-bit.\n\n![](Does-register-selection-matter-to-performance-on-x86-CPUs/PRS1.png)\n```c\nMOV   AL,  BYTE PTR [RDI]\nMOV   EBX, EAX // partial register stall\n\nMOVZX EBX, BYTE PTR [RDI]\nAND   EAX, 0xFFFFFF00\nOR    EBX, EAX // no partial register stall\n\nMOVZX EAX, BYTE PTR [RDI]\nMOV   EBX, EAX // no partial register stall\n```\nPartial register stall is relatively easy to detect on general-purpose registers, but similar problems could happen on FLAGS registers and that is pretty covert. Certain instructions like `CMP` update all bits of FLAGS as the execution results, but `INC` and `DEC` write into FLAGS except `CF`. So, if `JCC` directly use FLAGS content from `INC`/`DEC`, `JCC` would possibly have false dependency from unexpected instructions.\n```c\nCMP EDX, DWORD PTR [EBP]\n...\nINC ECX\nJBE LBB_XXX // JBE reads CF and ZF,  so there would be a false dependency from CMP\n```\nConsequently, on certain Intel architectures, compilers usually do not generate `INC`/`DEC` for loop count updating (i.e., `i++` of `for (int i = N; i != 0; i--)`) or reuse the `INC`/`DEC` produced FLAGS on `JCC`. On the flip side, that would increase the code size and make I-cache issues. Fortunately, Intel has fixed the partial register stall on FLAGS since [SandyBridge](https://en.wikipedia.org/wiki/Sandy_Bridge). But that still exists on most of the mainstream ATOM CPUs.\n\n![](Does-register-selection-matter-to-performance-on-x86-CPUs/PRS2.png)\n\nSo far, you may already think of SIMD registers. Yes, the partial register stall also occurs on SIMD registers. \n\n![](Does-register-selection-matter-to-performance-on-x86-CPUs/PRS3.png)\n\nBut partial SIMD/FLAGS register stall is an instruction selection issue instead of register selection. Let's finish this section and move on.\n\n## Architecture Bugs  \nCertain Intel architectures (SandyBridge, Haswell, and Skylake) have [a bug](https://stackoverflow.com/questions/21390165/why-does-breaking-the-output-dependency-of-lzcnt-matter) on three instructions - `LZCNT`, `TZCNT`, and `POPCNT`. These three instructions all have 2 operands (1 source register and 1 destination register), but they are different from most of the other 2-operand instructions like `ADD`. `ADD` reads its source __and__ destination, and stores the result back to the destination register, which ADD-like instructions are called RMW (Read-Modify-Write). `LZCNT`, `TZCNT`, and `POPCNT` are not RWM that just read the source and write back to the destination. Due to some unknown reason, those Intel architectures incorrectly treat `LZCNT`, `TZCNT `, and `POPCNT` as the normal RWM instructions, which the `LZCNT`, `TZCNT `, and `POPCNT` have to wait for the computing results in both operands. Actually, only waiting for the source register getting done is enough.\n```c\nPOPCNT  RCX, QWORD PTR [RDI]\n...\nPOPCNT  RCX, QWORD PTR [RDI+8]\n```\nAssume the above code is compiled from an unrolled loop that iteratively computes bit-count on an array. Since each `POPCNT` operates over a non-overlapped `Int64` element, so the two `POPCNT` should execute totally in parallel. In other words, unrolling the loop by `2` iterations can make it at least 2x faster. However, that does not happen because Intel CPUs think that the second `POPCNT` needs to read `RCX` that written by the first `POPCNT`. So, the two `POPCNT` never gets parallel running.\n\nTo solve this problem, we can change the `POPCNT` to use a dependency-free register as the destination, but that usually complicates the compiler's register allocation too much. A simpler solution is to force triggering register renaming on the destination register via zeroing it.\n```c\nXOR     RCX, RCX // Force CPU to assign a new physical register to RCX\nPOPCNT  RCX, QWORD PTR [RDI]\n...\nXOR     RCX, RCX // Force CPU to assign a new physical register to RCX\nPOPCNT  RCX, QWORD PTR [RDI+8]\n```\nZeroing `RCX` by `XOR RCX, RXC` or `SUB RCX, RCX` does not actually execute `XOR` or `SUB` operations that instructions just trigger register renaming to assign an empty register to `RCX`. Therefore, `XOR REG1, REG1` and `SUB REG1, REG1` do not reach the CPU pipeline stages behind register renaming, which makes the zeroing very cheap even though that increases CPU front-end pressures a bit.\n\n## SIMD Registers  \nIntel fulfills really awesome SIMD acceleration via SSE/AVX/AVX-512 ISA families. But there are more tricks on SIMD code generation than the scalar side. Most of the issues are not only about instruction/register selections but also impacted by instruction encoding, calling conventions, and hardware optimizations, etc.\n\nIntel introduced `VEX` encoding with AVX that allows instructions to have an additional register to make the destination non-destructive. That is really good for register allocation on new SIMD instructions. However, Intel made a `VEX` counterpart for every old SSE instruction even though non-SIMD floating-point instructions. Then something gets messed up.\n```c\nMOVAPS  XMM0, XMMWORD PTR [RDI]\n...\nVSQRTSS XMM0, XMM0, XMM1 // VSQRTSS XMM0, XMM1, XMM1 could be much faster\n```\n`SQRTSS XMM0, XMM1` computes the square root of the floating point number in `XMM1` and writes the result into `XMM0`. The VEX version `VSQRTSS` requires 3 register operands, which copies the upper 64-bit of the second operand to the result. That makes `VSQRTSS` has additional dependencies on the second operand. For example,  in the above code, `VSQRTSS XMM0, XMM0, XMM1` has to wait for loading data into `XMM0` but that is useless for scalar floating-point code. You may think that we can let compilers always reuse the 3rd register at the 2nd position, `VSQRTSS XMM0, XMM1, XMM1`, to break the dependency. However, that does not work when the 3rd operand directly from a memory location, like `VSQRTSS XMM0, XMM1, XMMWORD PTR [RDI]`. In that situation, a better solution would insert `XOR` to trigger the register renaming for dst.\n\nUsually, programmers think that using 256-bit YMM registers should get 2x faster than 128-bit XMM registers. Actually, that is not always true. Windows x64 calling conventions define [XMM0-XMM15 as callee saved registers](https://docs.microsoft.com/en-us/cpp/build/x64-calling-convention?view=vs-2019#callercallee-saved-registers), so using YMM0-YMM15 would cause more caller saving code than XMM registers. Moreover, Intel only implemented store forwarding for registers <= 128-bit, so that spilling YMM register could be more expensive than XMM. These additional overheads could reduce the benefits of using YMM.\n\n## One More Thing\nLook back at the very beginning code of this post, that seems not to fall into the above categories. But the 2 lines of code still may run in different performances. In the code section below, the comments show the instruction encoding, which means the binary representation of instructions in memory. We can see using `ADD` with `EAX` as dst register is 1-byte short than another, so that has higher code density and better cache-friendly.\n```c\nADD EAX, 0xffff0704 // 05 04 07 FF FF\nADD EBX, 0xffff0704 // 81 C3 04 07 FF FF\n```\nConsequently, even though selecting `EAX` or other registers (like `EBX`, `ECX`, `R8D`, etc.) does not directly change `ADD`'s latency/throughput, it is also possible to impact the whole program performance.","source":"_posts/Does-register-selection-matter-to-performance-on-x86-CPUs.md","raw":"---\ntitle: Does register selection matter to performance on x86 CPUs?\ndate: 2020-02-16 18:29:37\ntags:\n- x86\n- Compiler\n- Intel\ndescription:\n- Instruction selection is a critical portion in compilers, as different instructions could cause significant performance differences even though the semantics not changed. Does register selection also matter to performance (assume the register selection does not lead to less or more register spills)? Honestly, I never intentionally thought of this question until I came across it on Zhihu (a Chinese Q&A website). But this is a really interesting topic that reflects many tricks of assembly programming and compiler code generation. So, that deserves a blog to refresh my memory and give a share :)\n---\nInstruction selection is a critical portion in compilers, as different instructions could cause significant performance differences even though the semantics not changed. Does register selection also matter to performance (assume the register selection does not lead to less or more register spills)? Honestly, I never intentionally thought of this question until I came across it on Zhihu (a Chinese Q&A website). But this is a really interesting topic that reflects many tricks of assembly programming and compiler code generation. So, that deserves a blog to refresh my memory and give a share :) \n\nIn other words, the question is equivalent to \n> Is one of the instructions below faster than another one?  \n![](Does-register-selection-matter-to-performance-on-x86-CPUs/ADD.png)  \n\nAnd the question can be extended to any instruction of x86/x86-64 ISAs (not only on `ADD`).\n\nFrom undergraduate classes in CS departments, we know modern computer architectures usually have a pipeline stage called __register renaming__ that assigns real physical registers to the named logic register referred to in an assembly instruction. For example, the following code uses `EAX` twice but the two usages are not related to each other.\n```c\nADD EDX, EAX\nADD EAX, EBX\n```\nAssume this code is semantically correct. In practice, CPUs usually assign different physical registers to the two `EAX` for breaking [anti-dependency](https://en.wikipedia.org/wiki/Data_dependency#Anti-dependency). So they can parallel execute on pipelined superscalar CPUs, and `ADD EAX, EBX` does not have to worry about if writing over `EAX` impacts `ADD EDX, EAX`. __Therefore, we usually suppose different register names in assembly code do NOT cause performance difference on modern x86 CPUs.__\n\nIs the story over? No.\n\nThe above statements only hold for general cases. There are a lot of corner cases existing in the real world that our college courses never reached. CPUs are pearls of modern engineering and industry, which also have many corner cases breaking our common sense. So, different register names will impact performance a lot, sometimes. I collected these corner cases in four categories. \n\n> Note, the rest of the article only talks about Intel micro-architectures. \n\n## Special Instructions \nA few instructions are executing slower with certain logic registers due to micro-architecture limitations. The most famous one is `LEA`. \n`LEA` was designed to leverage the complex and powerful x86 addressing-mode in wider areas, such as arithmetic computations, which requires fewer registers for intermediate results than arithmetic instructions. However, certain forms of `LEA` only can be executed on port1, which those `LEA` forms with lower ILP and higher latency are called __slow LEA__. According to the Intel optimization manual, using `EBP`, `RBP`, or `R13` as the base address will make LEA slower.\n  \n![](Does-register-selection-matter-to-performance-on-x86-CPUs/LEA.png)\n\nAlthough compilers could assign other registers to the base address variables, sometimes that is impossible in register allocations and there are more forms of slow LEAs that cannot be improved by register selection. Hence, in general, compilers avoid generating slow LEAs by (1) replacing `LEA` by equivalent instruction sequences that may need more temporary registers or (2) folding `LEA` into its user instructions' addressing modes.\n\n## Partial Register Stall  \nMost kinds of x86 registers (e.g., general-purpose registers, FLAGS, and SIMD registers, etc.) can be accessed by multiple granularities. For instance, `RAX` can be partially accessed via `EAX`, `AX`, `AH`, and `AL`. Accessing `AL` is independent of `AH` on Intel CPUs, but reading `EAX` content that written though `AL` has significant performance degradation (5-6 cycles of latency). Consequently, Intel suggests always using registers with sizes of 32- or 64-bit.\n\n![](Does-register-selection-matter-to-performance-on-x86-CPUs/PRS1.png)\n```c\nMOV   AL,  BYTE PTR [RDI]\nMOV   EBX, EAX // partial register stall\n\nMOVZX EBX, BYTE PTR [RDI]\nAND   EAX, 0xFFFFFF00\nOR    EBX, EAX // no partial register stall\n\nMOVZX EAX, BYTE PTR [RDI]\nMOV   EBX, EAX // no partial register stall\n```\nPartial register stall is relatively easy to detect on general-purpose registers, but similar problems could happen on FLAGS registers and that is pretty covert. Certain instructions like `CMP` update all bits of FLAGS as the execution results, but `INC` and `DEC` write into FLAGS except `CF`. So, if `JCC` directly use FLAGS content from `INC`/`DEC`, `JCC` would possibly have false dependency from unexpected instructions.\n```c\nCMP EDX, DWORD PTR [EBP]\n...\nINC ECX\nJBE LBB_XXX // JBE reads CF and ZF,  so there would be a false dependency from CMP\n```\nConsequently, on certain Intel architectures, compilers usually do not generate `INC`/`DEC` for loop count updating (i.e., `i++` of `for (int i = N; i != 0; i--)`) or reuse the `INC`/`DEC` produced FLAGS on `JCC`. On the flip side, that would increase the code size and make I-cache issues. Fortunately, Intel has fixed the partial register stall on FLAGS since [SandyBridge](https://en.wikipedia.org/wiki/Sandy_Bridge). But that still exists on most of the mainstream ATOM CPUs.\n\n![](Does-register-selection-matter-to-performance-on-x86-CPUs/PRS2.png)\n\nSo far, you may already think of SIMD registers. Yes, the partial register stall also occurs on SIMD registers. \n\n![](Does-register-selection-matter-to-performance-on-x86-CPUs/PRS3.png)\n\nBut partial SIMD/FLAGS register stall is an instruction selection issue instead of register selection. Let's finish this section and move on.\n\n## Architecture Bugs  \nCertain Intel architectures (SandyBridge, Haswell, and Skylake) have [a bug](https://stackoverflow.com/questions/21390165/why-does-breaking-the-output-dependency-of-lzcnt-matter) on three instructions - `LZCNT`, `TZCNT`, and `POPCNT`. These three instructions all have 2 operands (1 source register and 1 destination register), but they are different from most of the other 2-operand instructions like `ADD`. `ADD` reads its source __and__ destination, and stores the result back to the destination register, which ADD-like instructions are called RMW (Read-Modify-Write). `LZCNT`, `TZCNT`, and `POPCNT` are not RWM that just read the source and write back to the destination. Due to some unknown reason, those Intel architectures incorrectly treat `LZCNT`, `TZCNT `, and `POPCNT` as the normal RWM instructions, which the `LZCNT`, `TZCNT `, and `POPCNT` have to wait for the computing results in both operands. Actually, only waiting for the source register getting done is enough.\n```c\nPOPCNT  RCX, QWORD PTR [RDI]\n...\nPOPCNT  RCX, QWORD PTR [RDI+8]\n```\nAssume the above code is compiled from an unrolled loop that iteratively computes bit-count on an array. Since each `POPCNT` operates over a non-overlapped `Int64` element, so the two `POPCNT` should execute totally in parallel. In other words, unrolling the loop by `2` iterations can make it at least 2x faster. However, that does not happen because Intel CPUs think that the second `POPCNT` needs to read `RCX` that written by the first `POPCNT`. So, the two `POPCNT` never gets parallel running.\n\nTo solve this problem, we can change the `POPCNT` to use a dependency-free register as the destination, but that usually complicates the compiler's register allocation too much. A simpler solution is to force triggering register renaming on the destination register via zeroing it.\n```c\nXOR     RCX, RCX // Force CPU to assign a new physical register to RCX\nPOPCNT  RCX, QWORD PTR [RDI]\n...\nXOR     RCX, RCX // Force CPU to assign a new physical register to RCX\nPOPCNT  RCX, QWORD PTR [RDI+8]\n```\nZeroing `RCX` by `XOR RCX, RXC` or `SUB RCX, RCX` does not actually execute `XOR` or `SUB` operations that instructions just trigger register renaming to assign an empty register to `RCX`. Therefore, `XOR REG1, REG1` and `SUB REG1, REG1` do not reach the CPU pipeline stages behind register renaming, which makes the zeroing very cheap even though that increases CPU front-end pressures a bit.\n\n## SIMD Registers  \nIntel fulfills really awesome SIMD acceleration via SSE/AVX/AVX-512 ISA families. But there are more tricks on SIMD code generation than the scalar side. Most of the issues are not only about instruction/register selections but also impacted by instruction encoding, calling conventions, and hardware optimizations, etc.\n\nIntel introduced `VEX` encoding with AVX that allows instructions to have an additional register to make the destination non-destructive. That is really good for register allocation on new SIMD instructions. However, Intel made a `VEX` counterpart for every old SSE instruction even though non-SIMD floating-point instructions. Then something gets messed up.\n```c\nMOVAPS  XMM0, XMMWORD PTR [RDI]\n...\nVSQRTSS XMM0, XMM0, XMM1 // VSQRTSS XMM0, XMM1, XMM1 could be much faster\n```\n`SQRTSS XMM0, XMM1` computes the square root of the floating point number in `XMM1` and writes the result into `XMM0`. The VEX version `VSQRTSS` requires 3 register operands, which copies the upper 64-bit of the second operand to the result. That makes `VSQRTSS` has additional dependencies on the second operand. For example,  in the above code, `VSQRTSS XMM0, XMM0, XMM1` has to wait for loading data into `XMM0` but that is useless for scalar floating-point code. You may think that we can let compilers always reuse the 3rd register at the 2nd position, `VSQRTSS XMM0, XMM1, XMM1`, to break the dependency. However, that does not work when the 3rd operand directly from a memory location, like `VSQRTSS XMM0, XMM1, XMMWORD PTR [RDI]`. In that situation, a better solution would insert `XOR` to trigger the register renaming for dst.\n\nUsually, programmers think that using 256-bit YMM registers should get 2x faster than 128-bit XMM registers. Actually, that is not always true. Windows x64 calling conventions define [XMM0-XMM15 as callee saved registers](https://docs.microsoft.com/en-us/cpp/build/x64-calling-convention?view=vs-2019#callercallee-saved-registers), so using YMM0-YMM15 would cause more caller saving code than XMM registers. Moreover, Intel only implemented store forwarding for registers <= 128-bit, so that spilling YMM register could be more expensive than XMM. These additional overheads could reduce the benefits of using YMM.\n\n## One More Thing\nLook back at the very beginning code of this post, that seems not to fall into the above categories. But the 2 lines of code still may run in different performances. In the code section below, the comments show the instruction encoding, which means the binary representation of instructions in memory. We can see using `ADD` with `EAX` as dst register is 1-byte short than another, so that has higher code density and better cache-friendly.\n```c\nADD EAX, 0xffff0704 // 05 04 07 FF FF\nADD EBX, 0xffff0704 // 81 C3 04 07 FF FF\n```\nConsequently, even though selecting `EAX` or other registers (like `EBX`, `ECX`, `R8D`, etc.) does not directly change `ADD`'s latency/throughput, it is also possible to impact the whole program performance.","slug":"Does-register-selection-matter-to-performance-on-x86-CPUs","published":1,"updated":"2023-04-16T08:05:50.135Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clgj4x0br00019tne4sz6gw4u","content":"<p>Instruction selection is a critical portion in compilers, as different instructions could cause significant performance differences even though the semantics not changed. Does register selection also matter to performance (assume the register selection does not lead to less or more register spills)? Honestly, I never intentionally thought of this question until I came across it on Zhihu (a Chinese Q&amp;A website). But this is a really interesting topic that reflects many tricks of assembly programming and compiler code generation. So, that deserves a blog to refresh my memory and give a share :) </p>\n<p>In other words, the question is equivalent to </p>\n<blockquote>\n<p>Is one of the instructions below faster than another one?<br><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/ADD.png\">  </p>\n</blockquote>\n<p>And the question can be extended to any instruction of x86&#x2F;x86-64 ISAs (not only on <code>ADD</code>).</p>\n<p>From undergraduate classes in CS departments, we know modern computer architectures usually have a pipeline stage called <strong>register renaming</strong> that assigns real physical registers to the named logic register referred to in an assembly instruction. For example, the following code uses <code>EAX</code> twice but the two usages are not related to each other.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD EDX, EAX</span><br><span class=\"line\">ADD EAX, EBX</span><br></pre></td></tr></table></figure>\n<p>Assume this code is semantically correct. In practice, CPUs usually assign different physical registers to the two <code>EAX</code> for breaking <a href=\"https://en.wikipedia.org/wiki/Data_dependency#Anti-dependency\">anti-dependency</a>. So they can parallel execute on pipelined superscalar CPUs, and <code>ADD EAX, EBX</code> does not have to worry about if writing over <code>EAX</code> impacts <code>ADD EDX, EAX</code>. <strong>Therefore, we usually suppose different register names in assembly code do NOT cause performance difference on modern x86 CPUs.</strong></p>\n<p>Is the story over? No.</p>\n<p>The above statements only hold for general cases. There are a lot of corner cases existing in the real world that our college courses never reached. CPUs are pearls of modern engineering and industry, which also have many corner cases breaking our common sense. So, different register names will impact performance a lot, sometimes. I collected these corner cases in four categories. </p>\n<blockquote>\n<p>Note, the rest of the article only talks about Intel micro-architectures. </p>\n</blockquote>\n<h2 id=\"Special-Instructions\"><a href=\"#Special-Instructions\" class=\"headerlink\" title=\"Special Instructions\"></a>Special Instructions</h2><p>A few instructions are executing slower with certain logic registers due to micro-architecture limitations. The most famous one is <code>LEA</code>.<br><code>LEA</code> was designed to leverage the complex and powerful x86 addressing-mode in wider areas, such as arithmetic computations, which requires fewer registers for intermediate results than arithmetic instructions. However, certain forms of <code>LEA</code> only can be executed on port1, which those <code>LEA</code> forms with lower ILP and higher latency are called <strong>slow LEA</strong>. According to the Intel optimization manual, using <code>EBP</code>, <code>RBP</code>, or <code>R13</code> as the base address will make LEA slower.</p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/LEA.png\"></p>\n<p>Although compilers could assign other registers to the base address variables, sometimes that is impossible in register allocations and there are more forms of slow LEAs that cannot be improved by register selection. Hence, in general, compilers avoid generating slow LEAs by (1) replacing <code>LEA</code> by equivalent instruction sequences that may need more temporary registers or (2) folding <code>LEA</code> into its user instructions’ addressing modes.</p>\n<h2 id=\"Partial-Register-Stall\"><a href=\"#Partial-Register-Stall\" class=\"headerlink\" title=\"Partial Register Stall\"></a>Partial Register Stall</h2><p>Most kinds of x86 registers (e.g., general-purpose registers, FLAGS, and SIMD registers, etc.) can be accessed by multiple granularities. For instance, <code>RAX</code> can be partially accessed via <code>EAX</code>, <code>AX</code>, <code>AH</code>, and <code>AL</code>. Accessing <code>AL</code> is independent of <code>AH</code> on Intel CPUs, but reading <code>EAX</code> content that written though <code>AL</code> has significant performance degradation (5-6 cycles of latency). Consequently, Intel suggests always using registers with sizes of 32- or 64-bit.</p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS1.png\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MOV   AL,  BYTE PTR [RDI]</span><br><span class=\"line\">MOV   EBX, EAX <span class=\"comment\">// partial register stall</span></span><br><span class=\"line\"></span><br><span class=\"line\">MOVZX EBX, BYTE PTR [RDI]</span><br><span class=\"line\">AND   EAX, <span class=\"number\">0xFFFFFF00</span></span><br><span class=\"line\">OR    EBX, EAX <span class=\"comment\">// no partial register stall</span></span><br><span class=\"line\"></span><br><span class=\"line\">MOVZX EAX, BYTE PTR [RDI]</span><br><span class=\"line\">MOV   EBX, EAX <span class=\"comment\">// no partial register stall</span></span><br></pre></td></tr></table></figure>\n<p>Partial register stall is relatively easy to detect on general-purpose registers, but similar problems could happen on FLAGS registers and that is pretty covert. Certain instructions like <code>CMP</code> update all bits of FLAGS as the execution results, but <code>INC</code> and <code>DEC</code> write into FLAGS except <code>CF</code>. So, if <code>JCC</code> directly use FLAGS content from <code>INC</code>&#x2F;<code>DEC</code>, <code>JCC</code> would possibly have false dependency from unexpected instructions.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CMP EDX, DWORD PTR [EBP]</span><br><span class=\"line\">...</span><br><span class=\"line\">INC ECX</span><br><span class=\"line\">JBE LBB_XXX <span class=\"comment\">// JBE reads CF and ZF,  so there would be a false dependency from CMP</span></span><br></pre></td></tr></table></figure>\n<p>Consequently, on certain Intel architectures, compilers usually do not generate <code>INC</code>&#x2F;<code>DEC</code> for loop count updating (i.e., <code>i++</code> of <code>for (int i = N; i != 0; i--)</code>) or reuse the <code>INC</code>&#x2F;<code>DEC</code> produced FLAGS on <code>JCC</code>. On the flip side, that would increase the code size and make I-cache issues. Fortunately, Intel has fixed the partial register stall on FLAGS since <a href=\"https://en.wikipedia.org/wiki/Sandy_Bridge\">SandyBridge</a>. But that still exists on most of the mainstream ATOM CPUs.</p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS2.png\"></p>\n<p>So far, you may already think of SIMD registers. Yes, the partial register stall also occurs on SIMD registers. </p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS3.png\"></p>\n<p>But partial SIMD&#x2F;FLAGS register stall is an instruction selection issue instead of register selection. Let’s finish this section and move on.</p>\n<h2 id=\"Architecture-Bugs\"><a href=\"#Architecture-Bugs\" class=\"headerlink\" title=\"Architecture Bugs\"></a>Architecture Bugs</h2><p>Certain Intel architectures (SandyBridge, Haswell, and Skylake) have <a href=\"https://stackoverflow.com/questions/21390165/why-does-breaking-the-output-dependency-of-lzcnt-matter\">a bug</a> on three instructions - <code>LZCNT</code>, <code>TZCNT</code>, and <code>POPCNT</code>. These three instructions all have 2 operands (1 source register and 1 destination register), but they are different from most of the other 2-operand instructions like <code>ADD</code>. <code>ADD</code> reads its source <strong>and</strong> destination, and stores the result back to the destination register, which ADD-like instructions are called RMW (Read-Modify-Write). <code>LZCNT</code>, <code>TZCNT</code>, and <code>POPCNT</code> are not RWM that just read the source and write back to the destination. Due to some unknown reason, those Intel architectures incorrectly treat <code>LZCNT</code>, <code>TZCNT </code>, and <code>POPCNT</code> as the normal RWM instructions, which the <code>LZCNT</code>, <code>TZCNT </code>, and <code>POPCNT</code> have to wait for the computing results in both operands. Actually, only waiting for the source register getting done is enough.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI]</span><br><span class=\"line\">...</span><br><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI+<span class=\"number\">8</span>]</span><br></pre></td></tr></table></figure>\n<p>Assume the above code is compiled from an unrolled loop that iteratively computes bit-count on an array. Since each <code>POPCNT</code> operates over a non-overlapped <code>Int64</code> element, so the two <code>POPCNT</code> should execute totally in parallel. In other words, unrolling the loop by <code>2</code> iterations can make it at least 2x faster. However, that does not happen because Intel CPUs think that the second <code>POPCNT</code> needs to read <code>RCX</code> that written by the first <code>POPCNT</code>. So, the two <code>POPCNT</code> never gets parallel running.</p>\n<p>To solve this problem, we can change the <code>POPCNT</code> to use a dependency-free register as the destination, but that usually complicates the compiler’s register allocation too much. A simpler solution is to force triggering register renaming on the destination register via zeroing it.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">XOR     RCX, RCX <span class=\"comment\">// Force CPU to assign a new physical register to RCX</span></span><br><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI]</span><br><span class=\"line\">...</span><br><span class=\"line\">XOR     RCX, RCX <span class=\"comment\">// Force CPU to assign a new physical register to RCX</span></span><br><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI+<span class=\"number\">8</span>]</span><br></pre></td></tr></table></figure>\n<p>Zeroing <code>RCX</code> by <code>XOR RCX, RXC</code> or <code>SUB RCX, RCX</code> does not actually execute <code>XOR</code> or <code>SUB</code> operations that instructions just trigger register renaming to assign an empty register to <code>RCX</code>. Therefore, <code>XOR REG1, REG1</code> and <code>SUB REG1, REG1</code> do not reach the CPU pipeline stages behind register renaming, which makes the zeroing very cheap even though that increases CPU front-end pressures a bit.</p>\n<h2 id=\"SIMD-Registers\"><a href=\"#SIMD-Registers\" class=\"headerlink\" title=\"SIMD Registers\"></a>SIMD Registers</h2><p>Intel fulfills really awesome SIMD acceleration via SSE&#x2F;AVX&#x2F;AVX-512 ISA families. But there are more tricks on SIMD code generation than the scalar side. Most of the issues are not only about instruction&#x2F;register selections but also impacted by instruction encoding, calling conventions, and hardware optimizations, etc.</p>\n<p>Intel introduced <code>VEX</code> encoding with AVX that allows instructions to have an additional register to make the destination non-destructive. That is really good for register allocation on new SIMD instructions. However, Intel made a <code>VEX</code> counterpart for every old SSE instruction even though non-SIMD floating-point instructions. Then something gets messed up.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MOVAPS  XMM0, XMMWORD PTR [RDI]</span><br><span class=\"line\">...</span><br><span class=\"line\">VSQRTSS XMM0, XMM0, XMM1 <span class=\"comment\">// VSQRTSS XMM0, XMM1, XMM1 could be much faster</span></span><br></pre></td></tr></table></figure>\n<p><code>SQRTSS XMM0, XMM1</code> computes the square root of the floating point number in <code>XMM1</code> and writes the result into <code>XMM0</code>. The VEX version <code>VSQRTSS</code> requires 3 register operands, which copies the upper 64-bit of the second operand to the result. That makes <code>VSQRTSS</code> has additional dependencies on the second operand. For example,  in the above code, <code>VSQRTSS XMM0, XMM0, XMM1</code> has to wait for loading data into <code>XMM0</code> but that is useless for scalar floating-point code. You may think that we can let compilers always reuse the 3rd register at the 2nd position, <code>VSQRTSS XMM0, XMM1, XMM1</code>, to break the dependency. However, that does not work when the 3rd operand directly from a memory location, like <code>VSQRTSS XMM0, XMM1, XMMWORD PTR [RDI]</code>. In that situation, a better solution would insert <code>XOR</code> to trigger the register renaming for dst.</p>\n<p>Usually, programmers think that using 256-bit YMM registers should get 2x faster than 128-bit XMM registers. Actually, that is not always true. Windows x64 calling conventions define <a href=\"https://docs.microsoft.com/en-us/cpp/build/x64-calling-convention?view=vs-2019#callercallee-saved-registers\">XMM0-XMM15 as callee saved registers</a>, so using YMM0-YMM15 would cause more caller saving code than XMM registers. Moreover, Intel only implemented store forwarding for registers &lt;&#x3D; 128-bit, so that spilling YMM register could be more expensive than XMM. These additional overheads could reduce the benefits of using YMM.</p>\n<h2 id=\"One-More-Thing\"><a href=\"#One-More-Thing\" class=\"headerlink\" title=\"One More Thing\"></a>One More Thing</h2><p>Look back at the very beginning code of this post, that seems not to fall into the above categories. But the 2 lines of code still may run in different performances. In the code section below, the comments show the instruction encoding, which means the binary representation of instructions in memory. We can see using <code>ADD</code> with <code>EAX</code> as dst register is 1-byte short than another, so that has higher code density and better cache-friendly.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD EAX, <span class=\"number\">0xffff0704</span> <span class=\"comment\">// 05 04 07 FF FF</span></span><br><span class=\"line\">ADD EBX, <span class=\"number\">0xffff0704</span> <span class=\"comment\">// 81 C3 04 07 FF FF</span></span><br></pre></td></tr></table></figure>\n<p>Consequently, even though selecting <code>EAX</code> or other registers (like <code>EBX</code>, <code>ECX</code>, <code>R8D</code>, etc.) does not directly change <code>ADD</code>‘s latency&#x2F;throughput, it is also possible to impact the whole program performance.</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Instruction selection is a critical portion in compilers, as different instructions could cause significant performance differences even though the semantics not changed. Does register selection also matter to performance (assume the register selection does not lead to less or more register spills)? Honestly, I never intentionally thought of this question until I came across it on Zhihu (a Chinese Q&amp;A website). But this is a really interesting topic that reflects many tricks of assembly programming and compiler code generation. So, that deserves a blog to refresh my memory and give a share :) </p>\n<p>In other words, the question is equivalent to </p>\n<blockquote>\n<p>Is one of the instructions below faster than another one?<br><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/ADD.png\">  </p>\n</blockquote>\n<p>And the question can be extended to any instruction of x86&#x2F;x86-64 ISAs (not only on <code>ADD</code>).</p>\n<p>From undergraduate classes in CS departments, we know modern computer architectures usually have a pipeline stage called <strong>register renaming</strong> that assigns real physical registers to the named logic register referred to in an assembly instruction. For example, the following code uses <code>EAX</code> twice but the two usages are not related to each other.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD EDX, EAX</span><br><span class=\"line\">ADD EAX, EBX</span><br></pre></td></tr></table></figure>\n<p>Assume this code is semantically correct. In practice, CPUs usually assign different physical registers to the two <code>EAX</code> for breaking <a href=\"https://en.wikipedia.org/wiki/Data_dependency#Anti-dependency\">anti-dependency</a>. So they can parallel execute on pipelined superscalar CPUs, and <code>ADD EAX, EBX</code> does not have to worry about if writing over <code>EAX</code> impacts <code>ADD EDX, EAX</code>. <strong>Therefore, we usually suppose different register names in assembly code do NOT cause performance difference on modern x86 CPUs.</strong></p>\n<p>Is the story over? No.</p>\n<p>The above statements only hold for general cases. There are a lot of corner cases existing in the real world that our college courses never reached. CPUs are pearls of modern engineering and industry, which also have many corner cases breaking our common sense. So, different register names will impact performance a lot, sometimes. I collected these corner cases in four categories. </p>\n<blockquote>\n<p>Note, the rest of the article only talks about Intel micro-architectures. </p>\n</blockquote>\n<h2 id=\"Special-Instructions\"><a href=\"#Special-Instructions\" class=\"headerlink\" title=\"Special Instructions\"></a>Special Instructions</h2><p>A few instructions are executing slower with certain logic registers due to micro-architecture limitations. The most famous one is <code>LEA</code>.<br><code>LEA</code> was designed to leverage the complex and powerful x86 addressing-mode in wider areas, such as arithmetic computations, which requires fewer registers for intermediate results than arithmetic instructions. However, certain forms of <code>LEA</code> only can be executed on port1, which those <code>LEA</code> forms with lower ILP and higher latency are called <strong>slow LEA</strong>. According to the Intel optimization manual, using <code>EBP</code>, <code>RBP</code>, or <code>R13</code> as the base address will make LEA slower.</p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/LEA.png\"></p>\n<p>Although compilers could assign other registers to the base address variables, sometimes that is impossible in register allocations and there are more forms of slow LEAs that cannot be improved by register selection. Hence, in general, compilers avoid generating slow LEAs by (1) replacing <code>LEA</code> by equivalent instruction sequences that may need more temporary registers or (2) folding <code>LEA</code> into its user instructions’ addressing modes.</p>\n<h2 id=\"Partial-Register-Stall\"><a href=\"#Partial-Register-Stall\" class=\"headerlink\" title=\"Partial Register Stall\"></a>Partial Register Stall</h2><p>Most kinds of x86 registers (e.g., general-purpose registers, FLAGS, and SIMD registers, etc.) can be accessed by multiple granularities. For instance, <code>RAX</code> can be partially accessed via <code>EAX</code>, <code>AX</code>, <code>AH</code>, and <code>AL</code>. Accessing <code>AL</code> is independent of <code>AH</code> on Intel CPUs, but reading <code>EAX</code> content that written though <code>AL</code> has significant performance degradation (5-6 cycles of latency). Consequently, Intel suggests always using registers with sizes of 32- or 64-bit.</p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS1.png\"></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MOV   AL,  BYTE PTR [RDI]</span><br><span class=\"line\">MOV   EBX, EAX <span class=\"comment\">// partial register stall</span></span><br><span class=\"line\"></span><br><span class=\"line\">MOVZX EBX, BYTE PTR [RDI]</span><br><span class=\"line\">AND   EAX, <span class=\"number\">0xFFFFFF00</span></span><br><span class=\"line\">OR    EBX, EAX <span class=\"comment\">// no partial register stall</span></span><br><span class=\"line\"></span><br><span class=\"line\">MOVZX EAX, BYTE PTR [RDI]</span><br><span class=\"line\">MOV   EBX, EAX <span class=\"comment\">// no partial register stall</span></span><br></pre></td></tr></table></figure>\n<p>Partial register stall is relatively easy to detect on general-purpose registers, but similar problems could happen on FLAGS registers and that is pretty covert. Certain instructions like <code>CMP</code> update all bits of FLAGS as the execution results, but <code>INC</code> and <code>DEC</code> write into FLAGS except <code>CF</code>. So, if <code>JCC</code> directly use FLAGS content from <code>INC</code>&#x2F;<code>DEC</code>, <code>JCC</code> would possibly have false dependency from unexpected instructions.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">CMP EDX, DWORD PTR [EBP]</span><br><span class=\"line\">...</span><br><span class=\"line\">INC ECX</span><br><span class=\"line\">JBE LBB_XXX <span class=\"comment\">// JBE reads CF and ZF,  so there would be a false dependency from CMP</span></span><br></pre></td></tr></table></figure>\n<p>Consequently, on certain Intel architectures, compilers usually do not generate <code>INC</code>&#x2F;<code>DEC</code> for loop count updating (i.e., <code>i++</code> of <code>for (int i = N; i != 0; i--)</code>) or reuse the <code>INC</code>&#x2F;<code>DEC</code> produced FLAGS on <code>JCC</code>. On the flip side, that would increase the code size and make I-cache issues. Fortunately, Intel has fixed the partial register stall on FLAGS since <a href=\"https://en.wikipedia.org/wiki/Sandy_Bridge\">SandyBridge</a>. But that still exists on most of the mainstream ATOM CPUs.</p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS2.png\"></p>\n<p>So far, you may already think of SIMD registers. Yes, the partial register stall also occurs on SIMD registers. </p>\n<p><img src=\"/2020/02/16/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS3.png\"></p>\n<p>But partial SIMD&#x2F;FLAGS register stall is an instruction selection issue instead of register selection. Let’s finish this section and move on.</p>\n<h2 id=\"Architecture-Bugs\"><a href=\"#Architecture-Bugs\" class=\"headerlink\" title=\"Architecture Bugs\"></a>Architecture Bugs</h2><p>Certain Intel architectures (SandyBridge, Haswell, and Skylake) have <a href=\"https://stackoverflow.com/questions/21390165/why-does-breaking-the-output-dependency-of-lzcnt-matter\">a bug</a> on three instructions - <code>LZCNT</code>, <code>TZCNT</code>, and <code>POPCNT</code>. These three instructions all have 2 operands (1 source register and 1 destination register), but they are different from most of the other 2-operand instructions like <code>ADD</code>. <code>ADD</code> reads its source <strong>and</strong> destination, and stores the result back to the destination register, which ADD-like instructions are called RMW (Read-Modify-Write). <code>LZCNT</code>, <code>TZCNT</code>, and <code>POPCNT</code> are not RWM that just read the source and write back to the destination. Due to some unknown reason, those Intel architectures incorrectly treat <code>LZCNT</code>, <code>TZCNT </code>, and <code>POPCNT</code> as the normal RWM instructions, which the <code>LZCNT</code>, <code>TZCNT </code>, and <code>POPCNT</code> have to wait for the computing results in both operands. Actually, only waiting for the source register getting done is enough.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI]</span><br><span class=\"line\">...</span><br><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI+<span class=\"number\">8</span>]</span><br></pre></td></tr></table></figure>\n<p>Assume the above code is compiled from an unrolled loop that iteratively computes bit-count on an array. Since each <code>POPCNT</code> operates over a non-overlapped <code>Int64</code> element, so the two <code>POPCNT</code> should execute totally in parallel. In other words, unrolling the loop by <code>2</code> iterations can make it at least 2x faster. However, that does not happen because Intel CPUs think that the second <code>POPCNT</code> needs to read <code>RCX</code> that written by the first <code>POPCNT</code>. So, the two <code>POPCNT</code> never gets parallel running.</p>\n<p>To solve this problem, we can change the <code>POPCNT</code> to use a dependency-free register as the destination, but that usually complicates the compiler’s register allocation too much. A simpler solution is to force triggering register renaming on the destination register via zeroing it.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">XOR     RCX, RCX <span class=\"comment\">// Force CPU to assign a new physical register to RCX</span></span><br><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI]</span><br><span class=\"line\">...</span><br><span class=\"line\">XOR     RCX, RCX <span class=\"comment\">// Force CPU to assign a new physical register to RCX</span></span><br><span class=\"line\">POPCNT  RCX, QWORD PTR [RDI+<span class=\"number\">8</span>]</span><br></pre></td></tr></table></figure>\n<p>Zeroing <code>RCX</code> by <code>XOR RCX, RXC</code> or <code>SUB RCX, RCX</code> does not actually execute <code>XOR</code> or <code>SUB</code> operations that instructions just trigger register renaming to assign an empty register to <code>RCX</code>. Therefore, <code>XOR REG1, REG1</code> and <code>SUB REG1, REG1</code> do not reach the CPU pipeline stages behind register renaming, which makes the zeroing very cheap even though that increases CPU front-end pressures a bit.</p>\n<h2 id=\"SIMD-Registers\"><a href=\"#SIMD-Registers\" class=\"headerlink\" title=\"SIMD Registers\"></a>SIMD Registers</h2><p>Intel fulfills really awesome SIMD acceleration via SSE&#x2F;AVX&#x2F;AVX-512 ISA families. But there are more tricks on SIMD code generation than the scalar side. Most of the issues are not only about instruction&#x2F;register selections but also impacted by instruction encoding, calling conventions, and hardware optimizations, etc.</p>\n<p>Intel introduced <code>VEX</code> encoding with AVX that allows instructions to have an additional register to make the destination non-destructive. That is really good for register allocation on new SIMD instructions. However, Intel made a <code>VEX</code> counterpart for every old SSE instruction even though non-SIMD floating-point instructions. Then something gets messed up.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MOVAPS  XMM0, XMMWORD PTR [RDI]</span><br><span class=\"line\">...</span><br><span class=\"line\">VSQRTSS XMM0, XMM0, XMM1 <span class=\"comment\">// VSQRTSS XMM0, XMM1, XMM1 could be much faster</span></span><br></pre></td></tr></table></figure>\n<p><code>SQRTSS XMM0, XMM1</code> computes the square root of the floating point number in <code>XMM1</code> and writes the result into <code>XMM0</code>. The VEX version <code>VSQRTSS</code> requires 3 register operands, which copies the upper 64-bit of the second operand to the result. That makes <code>VSQRTSS</code> has additional dependencies on the second operand. For example,  in the above code, <code>VSQRTSS XMM0, XMM0, XMM1</code> has to wait for loading data into <code>XMM0</code> but that is useless for scalar floating-point code. You may think that we can let compilers always reuse the 3rd register at the 2nd position, <code>VSQRTSS XMM0, XMM1, XMM1</code>, to break the dependency. However, that does not work when the 3rd operand directly from a memory location, like <code>VSQRTSS XMM0, XMM1, XMMWORD PTR [RDI]</code>. In that situation, a better solution would insert <code>XOR</code> to trigger the register renaming for dst.</p>\n<p>Usually, programmers think that using 256-bit YMM registers should get 2x faster than 128-bit XMM registers. Actually, that is not always true. Windows x64 calling conventions define <a href=\"https://docs.microsoft.com/en-us/cpp/build/x64-calling-convention?view=vs-2019#callercallee-saved-registers\">XMM0-XMM15 as callee saved registers</a>, so using YMM0-YMM15 would cause more caller saving code than XMM registers. Moreover, Intel only implemented store forwarding for registers &lt;&#x3D; 128-bit, so that spilling YMM register could be more expensive than XMM. These additional overheads could reduce the benefits of using YMM.</p>\n<h2 id=\"One-More-Thing\"><a href=\"#One-More-Thing\" class=\"headerlink\" title=\"One More Thing\"></a>One More Thing</h2><p>Look back at the very beginning code of this post, that seems not to fall into the above categories. But the 2 lines of code still may run in different performances. In the code section below, the comments show the instruction encoding, which means the binary representation of instructions in memory. We can see using <code>ADD</code> with <code>EAX</code> as dst register is 1-byte short than another, so that has higher code density and better cache-friendly.</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ADD EAX, <span class=\"number\">0xffff0704</span> <span class=\"comment\">// 05 04 07 FF FF</span></span><br><span class=\"line\">ADD EBX, <span class=\"number\">0xffff0704</span> <span class=\"comment\">// 81 C3 04 07 FF FF</span></span><br></pre></td></tr></table></figure>\n<p>Consequently, even though selecting <code>EAX</code> or other registers (like <code>EBX</code>, <code>ECX</code>, <code>R8D</code>, etc.) does not directly change <code>ADD</code>‘s latency&#x2F;throughput, it is also possible to impact the whole program performance.</p>\n"},{"title":"Hardware intrinsic in .NET Core 3.0 - Introduction","date":"2019-03-04T00:47:03.000Z","description":["Introduction to the new APIs of .NET Core 3.0 that allows lower level programming (e.g., SIMD programming) in C#."],"_content":"\nIn the past two years, I worked for Intel Corporation as a compiler engineer. The major project I worked during that period of time is to design and implement the x86 hardware intrinsic for .NET Core. This project was starting with the [design proposal](https://github.com/dotnet/corefx/issues/22940) at 8/2017, and now (3/2019) this feature is fully implemented in the JIT compiler/runtime and ready for release in .NET Core 3.0. That is my first job, I did much more things than what I expected and learned a lot from the open source cooperation. So, I decided to launch an English blog to share what I acquired from the open source work. In the future, I expect that this blog will have articles about compilers, language design, and computer graphics, but now let's start with .NET Core and hardware intrinsics.\n\n## Motivation\nComputer science is the fastest developing area in the last 50 years that has made so many fantasies come true. But why? The root reason is that our computer hardware and software become faster and faster at an incredible rate (a.k.a., [Moore's Law](https://en.wikipedia.org/wiki/Moore%27s_law)). As I remember, in my childhood, the most effective strategy of software optimization is \"waiting\". Just wait for newer CPUs that will run your applications much faster. However, the world is silently changing, and the \"free lunch\" become more and more expensive. So, computer scientists have looked for new directions to keep this growth rate, or in other words, to save this world. Stronger Data-Level Parallelism (DLP) is one of the mainstream development directions of contemporary general processors. Meanwhile, Single Instruction Multiple Data (SIMD) is the leading model of DLP on modern computer architectures due to its efficient compute power and economical resource requirement. However, most programming languages do not have proper abstractions for SIMD computing. For example, loop-auto-vectorization is a compiler optimization that tries to translate traditional scalar programs to vector instructions and totally hides the underlying SIMD architectures. However, this solution has been proven inefficient in practice, especially in restricted environments (e.g., dynamic compilation). On the other hand, directly exposing SIMD architectures to higher level languages without any abstraction (i.e., inline assembly) makes programming very difficult and compiler optimizations unavailable. Consequently, hardware intrinsic functions plays a balancing role between high-level abstraction and low-level assembly programming and achieves great success in C/C++ SIMD programming. \n\nIntrinsics are special functions that you cannot implement by yourself in the programming language that you are using. Hardware intrinsic functions are special functions that can be directly converted to a single (or a few) hardware instructions by the compiler, so that it exposes the underlying instruction architecture without abstraction overhead. Intrinsic functions perfectly integrate with other language features because they are just \"functions\". For example, intrinsic operates over variables instead of registers that assembly languages have but higher-level languages are not aware. Hardware intrinsics have been a native language (e.g., C/C++) feature for a long time. Although intrinsic functions can significantly improve the productivity of SIMD (or other hardware-dependent) programming, certain inherent drawbacks of native languages (e.g., manual memory management) make programming still difficult. Managed runtimes such as .NET Core are designed to improve programmer productivity and security by providing higher abstraction layers, type safety, and automatic memory management. This new feature, hardware intrinsics in .NET Core 3.0, combines the advantages of SIMD programming and managed languages (C#).\n\n## New Namespaces and Classes\nAs it was mentioned above, hardware intrinsics will be available as a formal and built-in feature in .NET Core 3.0 which exposes new namespaces, SIMD types, and classes representing different Instruction Set Architectures (ISA). The top-level namespaces are:\n1. `System.Runtime.Intrinsics`: contains SIMD types which abstract the underlying SIMD registers. `Vector128<T>` and `Vector256<T>` where `T` can be instantiated to any C# numeric type correspond to XMM and YMM registers on Intel ISA, respectively. This namespace also contains certain platform-agnostic convenience functions that provide common vector operations, e.g., initializing a vector with specified elements.\n2. `System.Runtime.Intrinsics.X86`: contains classes representing different Intel ISAs spanning SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, AVX, AVX2, FMA, LZCNT, POPCNT, BMI1, BMI2, PCLMULQDQ, and AES. For example, class `Avx` has many static methods that each of them maps to an AVX instruction. You can let the compiler generate `vaddps ymm, ymm, ymm` by calling `Avx.Add(vector1, vector2)` where `vector1/2` are instances of `Vector256<float>`. Particularity, each class has a boolean property called `IsSupported` which developers can use to check the underlying hardware support and contains intrinsic methods that operate over scalar or SIMD data. So, a hardware accelerated algorithm in .NET Core 3.0 usually has the top-level structure like below\n```csharp\nif (Avx2.IsSupported)\n{\n    // The AVX/AVX2 optimizing implementation for Intel Haswell or above CPUs  \n}\nelse if (Sse41.IsSupported)\n{\n    // The SSE optimizing implementation for older x86 CPUs  \n}\nelse if (Arm.Arm64.Simd.IsSupported)\n{\n    // The NEON optimizing implementation for ARM64 CPUs\n}\nelse\n{\n    // Scalar or software-fallback implementation\n}\n```\nIn this example, you may be curious about the `Arm.Arm64` path. Yes, .NET Core hardware intrinsic system also has the ARM counterpart (under namespace `System.Runtime.Intrinsics.Arm.Arm64`) that is originally designed and implemented by QCOM engineers. However, the progress of the ARM side is quite different from x86 in .NET Core 3.0, and its availability depends on the ARM64 version of .NET Core releasing. In this day, I am not sure about the status of ARM64 support in .NET Core 3.0, so please watch for Microsoft's official announcement if you want this feature on ARM. \n\n## SIMD Programming in .NET Core\nAlthough the hardware intrinsic system is not only about SIMD, the SIMD intrinsics are the most exciting part. So, I would like to give a simple SIMD example to demonstrate how to use hardware intrinsic in your C# programs. I will keep it as simple as possible. If you are interested in deeper knowledge about SIMD, I will dive into it in the next blog with lovely C# code.\n\nLet's `dotnet new` a console application template and copy the code below to `Program.cs` file. You do not need to install any NuGet package because hardware intrinsic is an official feature in the core library of .NET Core 3.0. So, please make sure you have .NET Core SDK 3.0 installed (before .NET Core 3.0 formally released, I recommend using the daily build).\n```csharp\nusing System.Runtime.Intrinsics;\nusing System.Runtime.Intrinsics.X86;\n\nstatic unsafe float[] SimdAdd(float[] a, float[] b, int n)\n{\n    float[] result = new float[n];\n    fixed(float* ptr_a = a, ptr_b = b, ptr_res = result)\n    {\n        for (int i = 0; i < n; i += Vector256<float>.Count)\n        {\n            Vector256<float> v1 = Avx.LoadVector256(ptr_a + i);\n            Vector256<float> v2 = Avx.LoadVector256(ptr_b + i);\n            Vector256<float> res = Avx.Add(v1, v2);\n            Avx.Store(ptr_res + i, res);\n        }\n    }\n    return result;\n}\n```\nThis function adds two arrays and returns the sum in a new array. This function is not real product code, it is simplified for demo only. Firstly, we need `using` two namespaces. As mentioned above, `System.Runtime.Intrinsics` is for `Vector256<float>` in this program, and `System.Runtime.Intrinsics.X86` is for using `Avx` intrinsics (e.g., `Avx.LoadVector256(ptr_a + i)`). Secondly, this function, `SimdAdd` has to be defined with `unsafe` keyword because `Avx.LoadVector256` and `Avx.Store` operates over \"pointers\" to read the input data and write the computation result back to memory. Overall, we have two kinds of hardware intrinsics under `System.Runtime.Intrinsics.X86` namespace:\n1. Computing intrinsics: this is the major group of intrinsic APIs. Usually, they take parameters with  SIMD types (`Vector128<T>`, `Vector256<T>`, etc.) and/or scalar numeric types (`int`, `float`, `ushort`, etc), return a computing result. `Avx.Add` is a typical example of this group.\n2. Memory-access intrinsics: SIMD computing intrinsics accept input data that is already in vector variables. However, data is usually organized in memory/file with their own format/types rather than `Vector128<T>` and `Vector256<T>`. So, we need memory-access intrinsics to convert in-memory data between in-variable vectors. The most common memory-access intrinsics are `Sse.LoadVector128`, `Sse2.LoadVector128`, `Avx.LoadVector256`, and `Sse.Store`, `Sse2.Store`, `Avx.Store`. \n\nThe main functionality of `SimdAdd` is fulfilled by `Avx.Add` that takes two vectors of `float` (each vector contain 8 `float` numbers), adds `float` numbers 8-by-8 (256-bit/32-bit == 8), and puts the sum vector in a new `Vector256<float>` variable (`res`).\n\nFinally, preparing two input arrays and calling `SimdAdd` from another function (e.g., `Main`) to see the result\n```csharp\nif (Avx.IsSupported)\n{\n    sum = SimdAdd(a, b, 256);\n}\n```\nNote, please check the hardware capability (by `IsSupported`) before calling any platform-specific intrinsic. Executing hardware intrinsic on incorrect hardware platforms would throw `System.PlatformNotSupportedException`.\n```\n> dotnet run\n\nUnhandled Exception: System.PlatformNotSupportedException: Operation is not supported on this platform.\n   at System.Runtime.Intrinsics.X86.Avx.LoadVector256(Single* address)\n   at IntrinsicDemo.IntrinsicDemo.SimdAdd(Single[] a, Single[] b, Int32 n) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 30\n   at IntrinsicDemo.IntrinsicDemo.Main(String[] args) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 17\n```\n\nYou may wonder how I got such an old CPU that does not support AVX instructions for showing the above message. Actually, during developing this feature in JIT compiler, we have considered the situations that hardware specific programs are difficult to test for all the hardware. So, we provide several environment variables to save developers' money from purchasing old hardware for testing :). For example, you can set `COMPlus_EnableAVX=0` to disable AVX  (and newer ISAs that depend on AVX) in your .NET Core process. Then, the code path for older CPUs can be tested on new machines. .NET Core 3.0 has one such environment variable for each `x86` ISA (e.g., `COMPlus_EnableSSE41`, `COMPlus_EnableAVX2`, `COMPlus_EnableFMA`, etc.).\n\nAdditionally, you may think the `Simd.Add` code too verbose since every intrinsic call has a leading ISA name (`Avx.Add`). Fortunately, this verbose can be avoided by C# `using static`\n```csharp\nusing static System.Runtime.Intrinsics.X86.Avx;\n\n...\n\nVector256<float> v1 = LoadVector256(ptr_a + i);\nVector256<float> v2 = LoadVector256(ptr_b + i);\nVector256<float> res = Add(v1, v2);\nStore(ptr_res + i, res);\n```\nWe intentionally designed every intrinsic API to work with `using static` without conflicts, even if the program mixes intrinsics from different ISAs.\n\n## Further Studying\nThe hardware intrinsic system in .NET Core 3.0 is not only a bunch of new APIs, that also opens the door of low-level programming and high-performance computing for .NET Core programmers. So, I plan to write a series of blogs to introduce the intrinsic APIs, SIMD programming in C#, and JIT compiler optimizations. But you might have no patience to wait for the next article, no worries, here are some materials that help for further studying\n- API documentation: There is no formal documentation for hardware intrinsic yet before .NET Core 3.0 release. But everything in .NET Core is open source, you can take a look at the source code of these APIs at [here](https://github.com/dotnet/coreclr/tree/master/src/System.Private.CoreLib/shared/System/Runtime/Intrinsics/X86), which each API has comments that correspond to C/C++ intrinsic APIs and x86 assembly instructions. Then you can reuse the [C/C++ intrinsic API documentation provided by Intel](https://software.intel.com/sites/landingpage/IntrinsicsGuide/) that is pretty straightforward for developers who have C/C++ experience.\n- Performance analysis: Improving performance is the main purpose to use hardware intrinsic. [BecnmarkDotnet](https://benchmarkdotnet.org/articles/overview.html) is an open source profiler for .NET Core applications and it is easy to use. Meanwhile, I really like [Intel VTune](https://software.intel.com/en-us/vtune) that provides more sophisticated runtime hardware information, which is better for optimizing but understanding VTune output requires a bit of hardware knowledge.\n- More hardware intrinsic examples:  the .NET Core community has leveraged intrinsics to optimize the library code in [CoreFX](https://github.com/dotnet/corefx) and [CoreCLR](https://github.com/dotnet/coreclr) repos, watching related issues and PRs on GitHub is a good approach to learn. For example, [Ben Adams](https://github.com/benaadams)'s [PRs that vectorizing `IndexOf`](https://github.com/dotnet/coreclr/pull/22187#issuecomment-467872251). There are also some individual projects that heavily use hardware intrinsics, [SimdJsonSharp](https://github.com/EgorBo/SimdJsonSharp) is a C# port of SimdJson algorithm that accelerates JSON parsing using AVX2 instructions. [PacketTracer](https://github.com/fiigii/PacketTracer) is an SoA-vectorized ray tracing that is used to investigating .NET Core SIMD code generation quality.\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">PacketTracer is a SoA vectorized raytracer in .NET Core AVX intrinsic. We are using it to investigate CoreCLR SIMD code generation quality and it shows ~7x faster than the Vector3 AoS version. See <a href=\"https://t.co/ZHUmpvarwn\">https://t.co/ZHUmpvarwn</a> <a href=\"https://t.co/tHEqbijFNn\">pic.twitter.com/tHEqbijFNn</a></p>&mdash; Fei Peng (@fiigii) <a href=\"https://twitter.com/fiigii/status/1096512607471595520?ref_src=twsrc%5Etfw\">February 15, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n","source":"_posts/Hardware-intrinsic-in-NET-Core-3-0-Introduction.md","raw":"---\ntitle: Hardware intrinsic in .NET Core 3.0 - Introduction\ndate: 2019-03-03 16:47:03\ntags: \n- .NET Core\n- x86\n- SIMD\ndescription: \n- Introduction to the new APIs of .NET Core 3.0 that allows lower level programming (e.g., SIMD programming) in C#.\n---\n\nIn the past two years, I worked for Intel Corporation as a compiler engineer. The major project I worked during that period of time is to design and implement the x86 hardware intrinsic for .NET Core. This project was starting with the [design proposal](https://github.com/dotnet/corefx/issues/22940) at 8/2017, and now (3/2019) this feature is fully implemented in the JIT compiler/runtime and ready for release in .NET Core 3.0. That is my first job, I did much more things than what I expected and learned a lot from the open source cooperation. So, I decided to launch an English blog to share what I acquired from the open source work. In the future, I expect that this blog will have articles about compilers, language design, and computer graphics, but now let's start with .NET Core and hardware intrinsics.\n\n## Motivation\nComputer science is the fastest developing area in the last 50 years that has made so many fantasies come true. But why? The root reason is that our computer hardware and software become faster and faster at an incredible rate (a.k.a., [Moore's Law](https://en.wikipedia.org/wiki/Moore%27s_law)). As I remember, in my childhood, the most effective strategy of software optimization is \"waiting\". Just wait for newer CPUs that will run your applications much faster. However, the world is silently changing, and the \"free lunch\" become more and more expensive. So, computer scientists have looked for new directions to keep this growth rate, or in other words, to save this world. Stronger Data-Level Parallelism (DLP) is one of the mainstream development directions of contemporary general processors. Meanwhile, Single Instruction Multiple Data (SIMD) is the leading model of DLP on modern computer architectures due to its efficient compute power and economical resource requirement. However, most programming languages do not have proper abstractions for SIMD computing. For example, loop-auto-vectorization is a compiler optimization that tries to translate traditional scalar programs to vector instructions and totally hides the underlying SIMD architectures. However, this solution has been proven inefficient in practice, especially in restricted environments (e.g., dynamic compilation). On the other hand, directly exposing SIMD architectures to higher level languages without any abstraction (i.e., inline assembly) makes programming very difficult and compiler optimizations unavailable. Consequently, hardware intrinsic functions plays a balancing role between high-level abstraction and low-level assembly programming and achieves great success in C/C++ SIMD programming. \n\nIntrinsics are special functions that you cannot implement by yourself in the programming language that you are using. Hardware intrinsic functions are special functions that can be directly converted to a single (or a few) hardware instructions by the compiler, so that it exposes the underlying instruction architecture without abstraction overhead. Intrinsic functions perfectly integrate with other language features because they are just \"functions\". For example, intrinsic operates over variables instead of registers that assembly languages have but higher-level languages are not aware. Hardware intrinsics have been a native language (e.g., C/C++) feature for a long time. Although intrinsic functions can significantly improve the productivity of SIMD (or other hardware-dependent) programming, certain inherent drawbacks of native languages (e.g., manual memory management) make programming still difficult. Managed runtimes such as .NET Core are designed to improve programmer productivity and security by providing higher abstraction layers, type safety, and automatic memory management. This new feature, hardware intrinsics in .NET Core 3.0, combines the advantages of SIMD programming and managed languages (C#).\n\n## New Namespaces and Classes\nAs it was mentioned above, hardware intrinsics will be available as a formal and built-in feature in .NET Core 3.0 which exposes new namespaces, SIMD types, and classes representing different Instruction Set Architectures (ISA). The top-level namespaces are:\n1. `System.Runtime.Intrinsics`: contains SIMD types which abstract the underlying SIMD registers. `Vector128<T>` and `Vector256<T>` where `T` can be instantiated to any C# numeric type correspond to XMM and YMM registers on Intel ISA, respectively. This namespace also contains certain platform-agnostic convenience functions that provide common vector operations, e.g., initializing a vector with specified elements.\n2. `System.Runtime.Intrinsics.X86`: contains classes representing different Intel ISAs spanning SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, AVX, AVX2, FMA, LZCNT, POPCNT, BMI1, BMI2, PCLMULQDQ, and AES. For example, class `Avx` has many static methods that each of them maps to an AVX instruction. You can let the compiler generate `vaddps ymm, ymm, ymm` by calling `Avx.Add(vector1, vector2)` where `vector1/2` are instances of `Vector256<float>`. Particularity, each class has a boolean property called `IsSupported` which developers can use to check the underlying hardware support and contains intrinsic methods that operate over scalar or SIMD data. So, a hardware accelerated algorithm in .NET Core 3.0 usually has the top-level structure like below\n```csharp\nif (Avx2.IsSupported)\n{\n    // The AVX/AVX2 optimizing implementation for Intel Haswell or above CPUs  \n}\nelse if (Sse41.IsSupported)\n{\n    // The SSE optimizing implementation for older x86 CPUs  \n}\nelse if (Arm.Arm64.Simd.IsSupported)\n{\n    // The NEON optimizing implementation for ARM64 CPUs\n}\nelse\n{\n    // Scalar or software-fallback implementation\n}\n```\nIn this example, you may be curious about the `Arm.Arm64` path. Yes, .NET Core hardware intrinsic system also has the ARM counterpart (under namespace `System.Runtime.Intrinsics.Arm.Arm64`) that is originally designed and implemented by QCOM engineers. However, the progress of the ARM side is quite different from x86 in .NET Core 3.0, and its availability depends on the ARM64 version of .NET Core releasing. In this day, I am not sure about the status of ARM64 support in .NET Core 3.0, so please watch for Microsoft's official announcement if you want this feature on ARM. \n\n## SIMD Programming in .NET Core\nAlthough the hardware intrinsic system is not only about SIMD, the SIMD intrinsics are the most exciting part. So, I would like to give a simple SIMD example to demonstrate how to use hardware intrinsic in your C# programs. I will keep it as simple as possible. If you are interested in deeper knowledge about SIMD, I will dive into it in the next blog with lovely C# code.\n\nLet's `dotnet new` a console application template and copy the code below to `Program.cs` file. You do not need to install any NuGet package because hardware intrinsic is an official feature in the core library of .NET Core 3.0. So, please make sure you have .NET Core SDK 3.0 installed (before .NET Core 3.0 formally released, I recommend using the daily build).\n```csharp\nusing System.Runtime.Intrinsics;\nusing System.Runtime.Intrinsics.X86;\n\nstatic unsafe float[] SimdAdd(float[] a, float[] b, int n)\n{\n    float[] result = new float[n];\n    fixed(float* ptr_a = a, ptr_b = b, ptr_res = result)\n    {\n        for (int i = 0; i < n; i += Vector256<float>.Count)\n        {\n            Vector256<float> v1 = Avx.LoadVector256(ptr_a + i);\n            Vector256<float> v2 = Avx.LoadVector256(ptr_b + i);\n            Vector256<float> res = Avx.Add(v1, v2);\n            Avx.Store(ptr_res + i, res);\n        }\n    }\n    return result;\n}\n```\nThis function adds two arrays and returns the sum in a new array. This function is not real product code, it is simplified for demo only. Firstly, we need `using` two namespaces. As mentioned above, `System.Runtime.Intrinsics` is for `Vector256<float>` in this program, and `System.Runtime.Intrinsics.X86` is for using `Avx` intrinsics (e.g., `Avx.LoadVector256(ptr_a + i)`). Secondly, this function, `SimdAdd` has to be defined with `unsafe` keyword because `Avx.LoadVector256` and `Avx.Store` operates over \"pointers\" to read the input data and write the computation result back to memory. Overall, we have two kinds of hardware intrinsics under `System.Runtime.Intrinsics.X86` namespace:\n1. Computing intrinsics: this is the major group of intrinsic APIs. Usually, they take parameters with  SIMD types (`Vector128<T>`, `Vector256<T>`, etc.) and/or scalar numeric types (`int`, `float`, `ushort`, etc), return a computing result. `Avx.Add` is a typical example of this group.\n2. Memory-access intrinsics: SIMD computing intrinsics accept input data that is already in vector variables. However, data is usually organized in memory/file with their own format/types rather than `Vector128<T>` and `Vector256<T>`. So, we need memory-access intrinsics to convert in-memory data between in-variable vectors. The most common memory-access intrinsics are `Sse.LoadVector128`, `Sse2.LoadVector128`, `Avx.LoadVector256`, and `Sse.Store`, `Sse2.Store`, `Avx.Store`. \n\nThe main functionality of `SimdAdd` is fulfilled by `Avx.Add` that takes two vectors of `float` (each vector contain 8 `float` numbers), adds `float` numbers 8-by-8 (256-bit/32-bit == 8), and puts the sum vector in a new `Vector256<float>` variable (`res`).\n\nFinally, preparing two input arrays and calling `SimdAdd` from another function (e.g., `Main`) to see the result\n```csharp\nif (Avx.IsSupported)\n{\n    sum = SimdAdd(a, b, 256);\n}\n```\nNote, please check the hardware capability (by `IsSupported`) before calling any platform-specific intrinsic. Executing hardware intrinsic on incorrect hardware platforms would throw `System.PlatformNotSupportedException`.\n```\n> dotnet run\n\nUnhandled Exception: System.PlatformNotSupportedException: Operation is not supported on this platform.\n   at System.Runtime.Intrinsics.X86.Avx.LoadVector256(Single* address)\n   at IntrinsicDemo.IntrinsicDemo.SimdAdd(Single[] a, Single[] b, Int32 n) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 30\n   at IntrinsicDemo.IntrinsicDemo.Main(String[] args) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 17\n```\n\nYou may wonder how I got such an old CPU that does not support AVX instructions for showing the above message. Actually, during developing this feature in JIT compiler, we have considered the situations that hardware specific programs are difficult to test for all the hardware. So, we provide several environment variables to save developers' money from purchasing old hardware for testing :). For example, you can set `COMPlus_EnableAVX=0` to disable AVX  (and newer ISAs that depend on AVX) in your .NET Core process. Then, the code path for older CPUs can be tested on new machines. .NET Core 3.0 has one such environment variable for each `x86` ISA (e.g., `COMPlus_EnableSSE41`, `COMPlus_EnableAVX2`, `COMPlus_EnableFMA`, etc.).\n\nAdditionally, you may think the `Simd.Add` code too verbose since every intrinsic call has a leading ISA name (`Avx.Add`). Fortunately, this verbose can be avoided by C# `using static`\n```csharp\nusing static System.Runtime.Intrinsics.X86.Avx;\n\n...\n\nVector256<float> v1 = LoadVector256(ptr_a + i);\nVector256<float> v2 = LoadVector256(ptr_b + i);\nVector256<float> res = Add(v1, v2);\nStore(ptr_res + i, res);\n```\nWe intentionally designed every intrinsic API to work with `using static` without conflicts, even if the program mixes intrinsics from different ISAs.\n\n## Further Studying\nThe hardware intrinsic system in .NET Core 3.0 is not only a bunch of new APIs, that also opens the door of low-level programming and high-performance computing for .NET Core programmers. So, I plan to write a series of blogs to introduce the intrinsic APIs, SIMD programming in C#, and JIT compiler optimizations. But you might have no patience to wait for the next article, no worries, here are some materials that help for further studying\n- API documentation: There is no formal documentation for hardware intrinsic yet before .NET Core 3.0 release. But everything in .NET Core is open source, you can take a look at the source code of these APIs at [here](https://github.com/dotnet/coreclr/tree/master/src/System.Private.CoreLib/shared/System/Runtime/Intrinsics/X86), which each API has comments that correspond to C/C++ intrinsic APIs and x86 assembly instructions. Then you can reuse the [C/C++ intrinsic API documentation provided by Intel](https://software.intel.com/sites/landingpage/IntrinsicsGuide/) that is pretty straightforward for developers who have C/C++ experience.\n- Performance analysis: Improving performance is the main purpose to use hardware intrinsic. [BecnmarkDotnet](https://benchmarkdotnet.org/articles/overview.html) is an open source profiler for .NET Core applications and it is easy to use. Meanwhile, I really like [Intel VTune](https://software.intel.com/en-us/vtune) that provides more sophisticated runtime hardware information, which is better for optimizing but understanding VTune output requires a bit of hardware knowledge.\n- More hardware intrinsic examples:  the .NET Core community has leveraged intrinsics to optimize the library code in [CoreFX](https://github.com/dotnet/corefx) and [CoreCLR](https://github.com/dotnet/coreclr) repos, watching related issues and PRs on GitHub is a good approach to learn. For example, [Ben Adams](https://github.com/benaadams)'s [PRs that vectorizing `IndexOf`](https://github.com/dotnet/coreclr/pull/22187#issuecomment-467872251). There are also some individual projects that heavily use hardware intrinsics, [SimdJsonSharp](https://github.com/EgorBo/SimdJsonSharp) is a C# port of SimdJson algorithm that accelerates JSON parsing using AVX2 instructions. [PacketTracer](https://github.com/fiigii/PacketTracer) is an SoA-vectorized ray tracing that is used to investigating .NET Core SIMD code generation quality.\n<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">PacketTracer is a SoA vectorized raytracer in .NET Core AVX intrinsic. We are using it to investigate CoreCLR SIMD code generation quality and it shows ~7x faster than the Vector3 AoS version. See <a href=\"https://t.co/ZHUmpvarwn\">https://t.co/ZHUmpvarwn</a> <a href=\"https://t.co/tHEqbijFNn\">pic.twitter.com/tHEqbijFNn</a></p>&mdash; Fei Peng (@fiigii) <a href=\"https://twitter.com/fiigii/status/1096512607471595520?ref_src=twsrc%5Etfw\">February 15, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n","slug":"Hardware-intrinsic-in-NET-Core-3-0-Introduction","published":1,"updated":"2023-04-16T08:05:50.136Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clgj4x0bt00039tne14vu7tzf","content":"<p>In the past two years, I worked for Intel Corporation as a compiler engineer. The major project I worked during that period of time is to design and implement the x86 hardware intrinsic for .NET Core. This project was starting with the <a href=\"https://github.com/dotnet/corefx/issues/22940\">design proposal</a> at 8&#x2F;2017, and now (3&#x2F;2019) this feature is fully implemented in the JIT compiler&#x2F;runtime and ready for release in .NET Core 3.0. That is my first job, I did much more things than what I expected and learned a lot from the open source cooperation. So, I decided to launch an English blog to share what I acquired from the open source work. In the future, I expect that this blog will have articles about compilers, language design, and computer graphics, but now let’s start with .NET Core and hardware intrinsics.</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>Computer science is the fastest developing area in the last 50 years that has made so many fantasies come true. But why? The root reason is that our computer hardware and software become faster and faster at an incredible rate (a.k.a., <a href=\"https://en.wikipedia.org/wiki/Moore%27s_law\">Moore’s Law</a>). As I remember, in my childhood, the most effective strategy of software optimization is “waiting”. Just wait for newer CPUs that will run your applications much faster. However, the world is silently changing, and the “free lunch” become more and more expensive. So, computer scientists have looked for new directions to keep this growth rate, or in other words, to save this world. Stronger Data-Level Parallelism (DLP) is one of the mainstream development directions of contemporary general processors. Meanwhile, Single Instruction Multiple Data (SIMD) is the leading model of DLP on modern computer architectures due to its efficient compute power and economical resource requirement. However, most programming languages do not have proper abstractions for SIMD computing. For example, loop-auto-vectorization is a compiler optimization that tries to translate traditional scalar programs to vector instructions and totally hides the underlying SIMD architectures. However, this solution has been proven inefficient in practice, especially in restricted environments (e.g., dynamic compilation). On the other hand, directly exposing SIMD architectures to higher level languages without any abstraction (i.e., inline assembly) makes programming very difficult and compiler optimizations unavailable. Consequently, hardware intrinsic functions plays a balancing role between high-level abstraction and low-level assembly programming and achieves great success in C&#x2F;C++ SIMD programming. </p>\n<p>Intrinsics are special functions that you cannot implement by yourself in the programming language that you are using. Hardware intrinsic functions are special functions that can be directly converted to a single (or a few) hardware instructions by the compiler, so that it exposes the underlying instruction architecture without abstraction overhead. Intrinsic functions perfectly integrate with other language features because they are just “functions”. For example, intrinsic operates over variables instead of registers that assembly languages have but higher-level languages are not aware. Hardware intrinsics have been a native language (e.g., C&#x2F;C++) feature for a long time. Although intrinsic functions can significantly improve the productivity of SIMD (or other hardware-dependent) programming, certain inherent drawbacks of native languages (e.g., manual memory management) make programming still difficult. Managed runtimes such as .NET Core are designed to improve programmer productivity and security by providing higher abstraction layers, type safety, and automatic memory management. This new feature, hardware intrinsics in .NET Core 3.0, combines the advantages of SIMD programming and managed languages (C#).</p>\n<h2 id=\"New-Namespaces-and-Classes\"><a href=\"#New-Namespaces-and-Classes\" class=\"headerlink\" title=\"New Namespaces and Classes\"></a>New Namespaces and Classes</h2><p>As it was mentioned above, hardware intrinsics will be available as a formal and built-in feature in .NET Core 3.0 which exposes new namespaces, SIMD types, and classes representing different Instruction Set Architectures (ISA). The top-level namespaces are:</p>\n<ol>\n<li><code>System.Runtime.Intrinsics</code>: contains SIMD types which abstract the underlying SIMD registers. <code>Vector128&lt;T&gt;</code> and <code>Vector256&lt;T&gt;</code> where <code>T</code> can be instantiated to any C# numeric type correspond to XMM and YMM registers on Intel ISA, respectively. This namespace also contains certain platform-agnostic convenience functions that provide common vector operations, e.g., initializing a vector with specified elements.</li>\n<li><code>System.Runtime.Intrinsics.X86</code>: contains classes representing different Intel ISAs spanning SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, AVX, AVX2, FMA, LZCNT, POPCNT, BMI1, BMI2, PCLMULQDQ, and AES. For example, class <code>Avx</code> has many static methods that each of them maps to an AVX instruction. You can let the compiler generate <code>vaddps ymm, ymm, ymm</code> by calling <code>Avx.Add(vector1, vector2)</code> where <code>vector1/2</code> are instances of <code>Vector256&lt;float&gt;</code>. Particularity, each class has a boolean property called <code>IsSupported</code> which developers can use to check the underlying hardware support and contains intrinsic methods that operate over scalar or SIMD data. So, a hardware accelerated algorithm in .NET Core 3.0 usually has the top-level structure like below<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (Avx2.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// The AVX/AVX2 optimizing implementation for Intel Haswell or above CPUs  </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (Sse41.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// The SSE optimizing implementation for older x86 CPUs  </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (Arm.Arm64.Simd.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// The NEON optimizing implementation for ARM64 CPUs</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Scalar or software-fallback implementation</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\nIn this example, you may be curious about the <code>Arm.Arm64</code> path. Yes, .NET Core hardware intrinsic system also has the ARM counterpart (under namespace <code>System.Runtime.Intrinsics.Arm.Arm64</code>) that is originally designed and implemented by QCOM engineers. However, the progress of the ARM side is quite different from x86 in .NET Core 3.0, and its availability depends on the ARM64 version of .NET Core releasing. In this day, I am not sure about the status of ARM64 support in .NET Core 3.0, so please watch for Microsoft’s official announcement if you want this feature on ARM.</li>\n</ol>\n<h2 id=\"SIMD-Programming-in-NET-Core\"><a href=\"#SIMD-Programming-in-NET-Core\" class=\"headerlink\" title=\"SIMD Programming in .NET Core\"></a>SIMD Programming in .NET Core</h2><p>Although the hardware intrinsic system is not only about SIMD, the SIMD intrinsics are the most exciting part. So, I would like to give a simple SIMD example to demonstrate how to use hardware intrinsic in your C# programs. I will keep it as simple as possible. If you are interested in deeper knowledge about SIMD, I will dive into it in the next blog with lovely C# code.</p>\n<p>Let’s <code>dotnet new</code> a console application template and copy the code below to <code>Program.cs</code> file. You do not need to install any NuGet package because hardware intrinsic is an official feature in the core library of .NET Core 3.0. So, please make sure you have .NET Core SDK 3.0 installed (before .NET Core 3.0 formally released, I recommend using the daily build).</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">using</span> System.Runtime.Intrinsics;</span><br><span class=\"line\"><span class=\"keyword\">using</span> System.Runtime.Intrinsics.X86;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">unsafe</span> <span class=\"built_in\">float</span>[] <span class=\"title\">SimdAdd</span>(<span class=\"params\"><span class=\"built_in\">float</span>[] a, <span class=\"built_in\">float</span>[] b, <span class=\"built_in\">int</span> n</span>)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">float</span>[] result = <span class=\"keyword\">new</span> <span class=\"built_in\">float</span>[n];</span><br><span class=\"line\">    <span class=\"keyword\">fixed</span>(<span class=\"built_in\">float</span>* ptr_a = a, ptr_b = b, ptr_res = result)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"built_in\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i += Vector256&lt;<span class=\"built_in\">float</span>&gt;.Count)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            Vector256&lt;<span class=\"built_in\">float</span>&gt; v1 = Avx.LoadVector256(ptr_a + i);</span><br><span class=\"line\">            Vector256&lt;<span class=\"built_in\">float</span>&gt; v2 = Avx.LoadVector256(ptr_b + i);</span><br><span class=\"line\">            Vector256&lt;<span class=\"built_in\">float</span>&gt; res = Avx.Add(v1, v2);</span><br><span class=\"line\">            Avx.Store(ptr_res + i, res);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>This function adds two arrays and returns the sum in a new array. This function is not real product code, it is simplified for demo only. Firstly, we need <code>using</code> two namespaces. As mentioned above, <code>System.Runtime.Intrinsics</code> is for <code>Vector256&lt;float&gt;</code> in this program, and <code>System.Runtime.Intrinsics.X86</code> is for using <code>Avx</code> intrinsics (e.g., <code>Avx.LoadVector256(ptr_a + i)</code>). Secondly, this function, <code>SimdAdd</code> has to be defined with <code>unsafe</code> keyword because <code>Avx.LoadVector256</code> and <code>Avx.Store</code> operates over “pointers” to read the input data and write the computation result back to memory. Overall, we have two kinds of hardware intrinsics under <code>System.Runtime.Intrinsics.X86</code> namespace:</p>\n<ol>\n<li>Computing intrinsics: this is the major group of intrinsic APIs. Usually, they take parameters with  SIMD types (<code>Vector128&lt;T&gt;</code>, <code>Vector256&lt;T&gt;</code>, etc.) and&#x2F;or scalar numeric types (<code>int</code>, <code>float</code>, <code>ushort</code>, etc), return a computing result. <code>Avx.Add</code> is a typical example of this group.</li>\n<li>Memory-access intrinsics: SIMD computing intrinsics accept input data that is already in vector variables. However, data is usually organized in memory&#x2F;file with their own format&#x2F;types rather than <code>Vector128&lt;T&gt;</code> and <code>Vector256&lt;T&gt;</code>. So, we need memory-access intrinsics to convert in-memory data between in-variable vectors. The most common memory-access intrinsics are <code>Sse.LoadVector128</code>, <code>Sse2.LoadVector128</code>, <code>Avx.LoadVector256</code>, and <code>Sse.Store</code>, <code>Sse2.Store</code>, <code>Avx.Store</code>.</li>\n</ol>\n<p>The main functionality of <code>SimdAdd</code> is fulfilled by <code>Avx.Add</code> that takes two vectors of <code>float</code> (each vector contain 8 <code>float</code> numbers), adds <code>float</code> numbers 8-by-8 (256-bit&#x2F;32-bit &#x3D;&#x3D; 8), and puts the sum vector in a new <code>Vector256&lt;float&gt;</code> variable (<code>res</code>).</p>\n<p>Finally, preparing two input arrays and calling <code>SimdAdd</code> from another function (e.g., <code>Main</code>) to see the result</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (Avx.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    sum = SimdAdd(a, b, <span class=\"number\">256</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Note, please check the hardware capability (by <code>IsSupported</code>) before calling any platform-specific intrinsic. Executing hardware intrinsic on incorrect hardware platforms would throw <code>System.PlatformNotSupportedException</code>.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; dotnet run</span><br><span class=\"line\"></span><br><span class=\"line\">Unhandled Exception: System.PlatformNotSupportedException: Operation is not supported on this platform.</span><br><span class=\"line\">   at System.Runtime.Intrinsics.X86.Avx.LoadVector256(Single* address)</span><br><span class=\"line\">   at IntrinsicDemo.IntrinsicDemo.SimdAdd(Single[] a, Single[] b, Int32 n) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 30</span><br><span class=\"line\">   at IntrinsicDemo.IntrinsicDemo.Main(String[] args) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 17</span><br></pre></td></tr></table></figure>\n\n<p>You may wonder how I got such an old CPU that does not support AVX instructions for showing the above message. Actually, during developing this feature in JIT compiler, we have considered the situations that hardware specific programs are difficult to test for all the hardware. So, we provide several environment variables to save developers’ money from purchasing old hardware for testing :). For example, you can set <code>COMPlus_EnableAVX=0</code> to disable AVX  (and newer ISAs that depend on AVX) in your .NET Core process. Then, the code path for older CPUs can be tested on new machines. .NET Core 3.0 has one such environment variable for each <code>x86</code> ISA (e.g., <code>COMPlus_EnableSSE41</code>, <code>COMPlus_EnableAVX2</code>, <code>COMPlus_EnableFMA</code>, etc.).</p>\n<p>Additionally, you may think the <code>Simd.Add</code> code too verbose since every intrinsic call has a leading ISA name (<code>Avx.Add</code>). Fortunately, this verbose can be avoided by C# <code>using static</code></p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">static</span> System.Runtime.Intrinsics.X86.Avx;</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">Vector256&lt;<span class=\"built_in\">float</span>&gt; v1 = LoadVector256(ptr_a + i);</span><br><span class=\"line\">Vector256&lt;<span class=\"built_in\">float</span>&gt; v2 = LoadVector256(ptr_b + i);</span><br><span class=\"line\">Vector256&lt;<span class=\"built_in\">float</span>&gt; res = Add(v1, v2);</span><br><span class=\"line\">Store(ptr_res + i, res);</span><br></pre></td></tr></table></figure>\n<p>We intentionally designed every intrinsic API to work with <code>using static</code> without conflicts, even if the program mixes intrinsics from different ISAs.</p>\n<h2 id=\"Further-Studying\"><a href=\"#Further-Studying\" class=\"headerlink\" title=\"Further Studying\"></a>Further Studying</h2><p>The hardware intrinsic system in .NET Core 3.0 is not only a bunch of new APIs, that also opens the door of low-level programming and high-performance computing for .NET Core programmers. So, I plan to write a series of blogs to introduce the intrinsic APIs, SIMD programming in C#, and JIT compiler optimizations. But you might have no patience to wait for the next article, no worries, here are some materials that help for further studying</p>\n<ul>\n<li>API documentation: There is no formal documentation for hardware intrinsic yet before .NET Core 3.0 release. But everything in .NET Core is open source, you can take a look at the source code of these APIs at <a href=\"https://github.com/dotnet/coreclr/tree/master/src/System.Private.CoreLib/shared/System/Runtime/Intrinsics/X86\">here</a>, which each API has comments that correspond to C&#x2F;C++ intrinsic APIs and x86 assembly instructions. Then you can reuse the <a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/\">C&#x2F;C++ intrinsic API documentation provided by Intel</a> that is pretty straightforward for developers who have C&#x2F;C++ experience.</li>\n<li>Performance analysis: Improving performance is the main purpose to use hardware intrinsic. <a href=\"https://benchmarkdotnet.org/articles/overview.html\">BecnmarkDotnet</a> is an open source profiler for .NET Core applications and it is easy to use. Meanwhile, I really like <a href=\"https://software.intel.com/en-us/vtune\">Intel VTune</a> that provides more sophisticated runtime hardware information, which is better for optimizing but understanding VTune output requires a bit of hardware knowledge.</li>\n<li>More hardware intrinsic examples:  the .NET Core community has leveraged intrinsics to optimize the library code in <a href=\"https://github.com/dotnet/corefx\">CoreFX</a> and <a href=\"https://github.com/dotnet/coreclr\">CoreCLR</a> repos, watching related issues and PRs on GitHub is a good approach to learn. For example, <a href=\"https://github.com/benaadams\">Ben Adams</a>‘s <a href=\"https://github.com/dotnet/coreclr/pull/22187#issuecomment-467872251\">PRs that vectorizing <code>IndexOf</code></a>. There are also some individual projects that heavily use hardware intrinsics, <a href=\"https://github.com/EgorBo/SimdJsonSharp\">SimdJsonSharp</a> is a C# port of SimdJson algorithm that accelerates JSON parsing using AVX2 instructions. <a href=\"https://github.com/fiigii/PacketTracer\">PacketTracer</a> is an SoA-vectorized ray tracing that is used to investigating .NET Core SIMD code generation quality.<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">PacketTracer is a SoA vectorized raytracer in .NET Core AVX intrinsic. We are using it to investigate CoreCLR SIMD code generation quality and it shows ~7x faster than the Vector3 AoS version. See <a href=\"https://t.co/ZHUmpvarwn\">https://t.co/ZHUmpvarwn</a> <a href=\"https://t.co/tHEqbijFNn\">pic.twitter.com/tHEqbijFNn</a></p>&mdash; Fei Peng (@fiigii) <a href=\"https://twitter.com/fiigii/status/1096512607471595520?ref_src=twsrc%5Etfw\">February 15, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>In the past two years, I worked for Intel Corporation as a compiler engineer. The major project I worked during that period of time is to design and implement the x86 hardware intrinsic for .NET Core. This project was starting with the <a href=\"https://github.com/dotnet/corefx/issues/22940\">design proposal</a> at 8&#x2F;2017, and now (3&#x2F;2019) this feature is fully implemented in the JIT compiler&#x2F;runtime and ready for release in .NET Core 3.0. That is my first job, I did much more things than what I expected and learned a lot from the open source cooperation. So, I decided to launch an English blog to share what I acquired from the open source work. In the future, I expect that this blog will have articles about compilers, language design, and computer graphics, but now let’s start with .NET Core and hardware intrinsics.</p>\n<h2 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h2><p>Computer science is the fastest developing area in the last 50 years that has made so many fantasies come true. But why? The root reason is that our computer hardware and software become faster and faster at an incredible rate (a.k.a., <a href=\"https://en.wikipedia.org/wiki/Moore%27s_law\">Moore’s Law</a>). As I remember, in my childhood, the most effective strategy of software optimization is “waiting”. Just wait for newer CPUs that will run your applications much faster. However, the world is silently changing, and the “free lunch” become more and more expensive. So, computer scientists have looked for new directions to keep this growth rate, or in other words, to save this world. Stronger Data-Level Parallelism (DLP) is one of the mainstream development directions of contemporary general processors. Meanwhile, Single Instruction Multiple Data (SIMD) is the leading model of DLP on modern computer architectures due to its efficient compute power and economical resource requirement. However, most programming languages do not have proper abstractions for SIMD computing. For example, loop-auto-vectorization is a compiler optimization that tries to translate traditional scalar programs to vector instructions and totally hides the underlying SIMD architectures. However, this solution has been proven inefficient in practice, especially in restricted environments (e.g., dynamic compilation). On the other hand, directly exposing SIMD architectures to higher level languages without any abstraction (i.e., inline assembly) makes programming very difficult and compiler optimizations unavailable. Consequently, hardware intrinsic functions plays a balancing role between high-level abstraction and low-level assembly programming and achieves great success in C&#x2F;C++ SIMD programming. </p>\n<p>Intrinsics are special functions that you cannot implement by yourself in the programming language that you are using. Hardware intrinsic functions are special functions that can be directly converted to a single (or a few) hardware instructions by the compiler, so that it exposes the underlying instruction architecture without abstraction overhead. Intrinsic functions perfectly integrate with other language features because they are just “functions”. For example, intrinsic operates over variables instead of registers that assembly languages have but higher-level languages are not aware. Hardware intrinsics have been a native language (e.g., C&#x2F;C++) feature for a long time. Although intrinsic functions can significantly improve the productivity of SIMD (or other hardware-dependent) programming, certain inherent drawbacks of native languages (e.g., manual memory management) make programming still difficult. Managed runtimes such as .NET Core are designed to improve programmer productivity and security by providing higher abstraction layers, type safety, and automatic memory management. This new feature, hardware intrinsics in .NET Core 3.0, combines the advantages of SIMD programming and managed languages (C#).</p>\n<h2 id=\"New-Namespaces-and-Classes\"><a href=\"#New-Namespaces-and-Classes\" class=\"headerlink\" title=\"New Namespaces and Classes\"></a>New Namespaces and Classes</h2><p>As it was mentioned above, hardware intrinsics will be available as a formal and built-in feature in .NET Core 3.0 which exposes new namespaces, SIMD types, and classes representing different Instruction Set Architectures (ISA). The top-level namespaces are:</p>\n<ol>\n<li><code>System.Runtime.Intrinsics</code>: contains SIMD types which abstract the underlying SIMD registers. <code>Vector128&lt;T&gt;</code> and <code>Vector256&lt;T&gt;</code> where <code>T</code> can be instantiated to any C# numeric type correspond to XMM and YMM registers on Intel ISA, respectively. This namespace also contains certain platform-agnostic convenience functions that provide common vector operations, e.g., initializing a vector with specified elements.</li>\n<li><code>System.Runtime.Intrinsics.X86</code>: contains classes representing different Intel ISAs spanning SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, AVX, AVX2, FMA, LZCNT, POPCNT, BMI1, BMI2, PCLMULQDQ, and AES. For example, class <code>Avx</code> has many static methods that each of them maps to an AVX instruction. You can let the compiler generate <code>vaddps ymm, ymm, ymm</code> by calling <code>Avx.Add(vector1, vector2)</code> where <code>vector1/2</code> are instances of <code>Vector256&lt;float&gt;</code>. Particularity, each class has a boolean property called <code>IsSupported</code> which developers can use to check the underlying hardware support and contains intrinsic methods that operate over scalar or SIMD data. So, a hardware accelerated algorithm in .NET Core 3.0 usually has the top-level structure like below<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (Avx2.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// The AVX/AVX2 optimizing implementation for Intel Haswell or above CPUs  </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (Sse41.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// The SSE optimizing implementation for older x86 CPUs  </span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">else</span> <span class=\"keyword\">if</span> (Arm.Arm64.Simd.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// The NEON optimizing implementation for ARM64 CPUs</span></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"><span class=\"keyword\">else</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Scalar or software-fallback implementation</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\nIn this example, you may be curious about the <code>Arm.Arm64</code> path. Yes, .NET Core hardware intrinsic system also has the ARM counterpart (under namespace <code>System.Runtime.Intrinsics.Arm.Arm64</code>) that is originally designed and implemented by QCOM engineers. However, the progress of the ARM side is quite different from x86 in .NET Core 3.0, and its availability depends on the ARM64 version of .NET Core releasing. In this day, I am not sure about the status of ARM64 support in .NET Core 3.0, so please watch for Microsoft’s official announcement if you want this feature on ARM.</li>\n</ol>\n<h2 id=\"SIMD-Programming-in-NET-Core\"><a href=\"#SIMD-Programming-in-NET-Core\" class=\"headerlink\" title=\"SIMD Programming in .NET Core\"></a>SIMD Programming in .NET Core</h2><p>Although the hardware intrinsic system is not only about SIMD, the SIMD intrinsics are the most exciting part. So, I would like to give a simple SIMD example to demonstrate how to use hardware intrinsic in your C# programs. I will keep it as simple as possible. If you are interested in deeper knowledge about SIMD, I will dive into it in the next blog with lovely C# code.</p>\n<p>Let’s <code>dotnet new</code> a console application template and copy the code below to <code>Program.cs</code> file. You do not need to install any NuGet package because hardware intrinsic is an official feature in the core library of .NET Core 3.0. So, please make sure you have .NET Core SDK 3.0 installed (before .NET Core 3.0 formally released, I recommend using the daily build).</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">using</span> System.Runtime.Intrinsics;</span><br><span class=\"line\"><span class=\"keyword\">using</span> System.Runtime.Intrinsics.X86;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">static</span> <span class=\"keyword\">unsafe</span> <span class=\"built_in\">float</span>[] <span class=\"title\">SimdAdd</span>(<span class=\"params\"><span class=\"built_in\">float</span>[] a, <span class=\"built_in\">float</span>[] b, <span class=\"built_in\">int</span> n</span>)</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"built_in\">float</span>[] result = <span class=\"keyword\">new</span> <span class=\"built_in\">float</span>[n];</span><br><span class=\"line\">    <span class=\"keyword\">fixed</span>(<span class=\"built_in\">float</span>* ptr_a = a, ptr_b = b, ptr_res = result)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"built_in\">int</span> i = <span class=\"number\">0</span>; i &lt; n; i += Vector256&lt;<span class=\"built_in\">float</span>&gt;.Count)</span><br><span class=\"line\">        &#123;</span><br><span class=\"line\">            Vector256&lt;<span class=\"built_in\">float</span>&gt; v1 = Avx.LoadVector256(ptr_a + i);</span><br><span class=\"line\">            Vector256&lt;<span class=\"built_in\">float</span>&gt; v2 = Avx.LoadVector256(ptr_b + i);</span><br><span class=\"line\">            Vector256&lt;<span class=\"built_in\">float</span>&gt; res = Avx.Add(v1, v2);</span><br><span class=\"line\">            Avx.Store(ptr_res + i, res);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    <span class=\"keyword\">return</span> result;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>This function adds two arrays and returns the sum in a new array. This function is not real product code, it is simplified for demo only. Firstly, we need <code>using</code> two namespaces. As mentioned above, <code>System.Runtime.Intrinsics</code> is for <code>Vector256&lt;float&gt;</code> in this program, and <code>System.Runtime.Intrinsics.X86</code> is for using <code>Avx</code> intrinsics (e.g., <code>Avx.LoadVector256(ptr_a + i)</code>). Secondly, this function, <code>SimdAdd</code> has to be defined with <code>unsafe</code> keyword because <code>Avx.LoadVector256</code> and <code>Avx.Store</code> operates over “pointers” to read the input data and write the computation result back to memory. Overall, we have two kinds of hardware intrinsics under <code>System.Runtime.Intrinsics.X86</code> namespace:</p>\n<ol>\n<li>Computing intrinsics: this is the major group of intrinsic APIs. Usually, they take parameters with  SIMD types (<code>Vector128&lt;T&gt;</code>, <code>Vector256&lt;T&gt;</code>, etc.) and&#x2F;or scalar numeric types (<code>int</code>, <code>float</code>, <code>ushort</code>, etc), return a computing result. <code>Avx.Add</code> is a typical example of this group.</li>\n<li>Memory-access intrinsics: SIMD computing intrinsics accept input data that is already in vector variables. However, data is usually organized in memory&#x2F;file with their own format&#x2F;types rather than <code>Vector128&lt;T&gt;</code> and <code>Vector256&lt;T&gt;</code>. So, we need memory-access intrinsics to convert in-memory data between in-variable vectors. The most common memory-access intrinsics are <code>Sse.LoadVector128</code>, <code>Sse2.LoadVector128</code>, <code>Avx.LoadVector256</code>, and <code>Sse.Store</code>, <code>Sse2.Store</code>, <code>Avx.Store</code>.</li>\n</ol>\n<p>The main functionality of <code>SimdAdd</code> is fulfilled by <code>Avx.Add</code> that takes two vectors of <code>float</code> (each vector contain 8 <code>float</code> numbers), adds <code>float</code> numbers 8-by-8 (256-bit&#x2F;32-bit &#x3D;&#x3D; 8), and puts the sum vector in a new <code>Vector256&lt;float&gt;</code> variable (<code>res</code>).</p>\n<p>Finally, preparing two input arrays and calling <code>SimdAdd</code> from another function (e.g., <code>Main</code>) to see the result</p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span> (Avx.IsSupported)</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    sum = SimdAdd(a, b, <span class=\"number\">256</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>Note, please check the hardware capability (by <code>IsSupported</code>) before calling any platform-specific intrinsic. Executing hardware intrinsic on incorrect hardware platforms would throw <code>System.PlatformNotSupportedException</code>.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; dotnet run</span><br><span class=\"line\"></span><br><span class=\"line\">Unhandled Exception: System.PlatformNotSupportedException: Operation is not supported on this platform.</span><br><span class=\"line\">   at System.Runtime.Intrinsics.X86.Avx.LoadVector256(Single* address)</span><br><span class=\"line\">   at IntrinsicDemo.IntrinsicDemo.SimdAdd(Single[] a, Single[] b, Int32 n) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 30</span><br><span class=\"line\">   at IntrinsicDemo.IntrinsicDemo.Main(String[] args) in /Users/fiigii/workspace/test/IntrinsicDemo/Program.cs:line 17</span><br></pre></td></tr></table></figure>\n\n<p>You may wonder how I got such an old CPU that does not support AVX instructions for showing the above message. Actually, during developing this feature in JIT compiler, we have considered the situations that hardware specific programs are difficult to test for all the hardware. So, we provide several environment variables to save developers’ money from purchasing old hardware for testing :). For example, you can set <code>COMPlus_EnableAVX=0</code> to disable AVX  (and newer ISAs that depend on AVX) in your .NET Core process. Then, the code path for older CPUs can be tested on new machines. .NET Core 3.0 has one such environment variable for each <code>x86</code> ISA (e.g., <code>COMPlus_EnableSSE41</code>, <code>COMPlus_EnableAVX2</code>, <code>COMPlus_EnableFMA</code>, etc.).</p>\n<p>Additionally, you may think the <code>Simd.Add</code> code too verbose since every intrinsic call has a leading ISA name (<code>Avx.Add</code>). Fortunately, this verbose can be avoided by C# <code>using static</code></p>\n<figure class=\"highlight csharp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">static</span> System.Runtime.Intrinsics.X86.Avx;</span><br><span class=\"line\"></span><br><span class=\"line\">...</span><br><span class=\"line\"></span><br><span class=\"line\">Vector256&lt;<span class=\"built_in\">float</span>&gt; v1 = LoadVector256(ptr_a + i);</span><br><span class=\"line\">Vector256&lt;<span class=\"built_in\">float</span>&gt; v2 = LoadVector256(ptr_b + i);</span><br><span class=\"line\">Vector256&lt;<span class=\"built_in\">float</span>&gt; res = Add(v1, v2);</span><br><span class=\"line\">Store(ptr_res + i, res);</span><br></pre></td></tr></table></figure>\n<p>We intentionally designed every intrinsic API to work with <code>using static</code> without conflicts, even if the program mixes intrinsics from different ISAs.</p>\n<h2 id=\"Further-Studying\"><a href=\"#Further-Studying\" class=\"headerlink\" title=\"Further Studying\"></a>Further Studying</h2><p>The hardware intrinsic system in .NET Core 3.0 is not only a bunch of new APIs, that also opens the door of low-level programming and high-performance computing for .NET Core programmers. So, I plan to write a series of blogs to introduce the intrinsic APIs, SIMD programming in C#, and JIT compiler optimizations. But you might have no patience to wait for the next article, no worries, here are some materials that help for further studying</p>\n<ul>\n<li>API documentation: There is no formal documentation for hardware intrinsic yet before .NET Core 3.0 release. But everything in .NET Core is open source, you can take a look at the source code of these APIs at <a href=\"https://github.com/dotnet/coreclr/tree/master/src/System.Private.CoreLib/shared/System/Runtime/Intrinsics/X86\">here</a>, which each API has comments that correspond to C&#x2F;C++ intrinsic APIs and x86 assembly instructions. Then you can reuse the <a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/\">C&#x2F;C++ intrinsic API documentation provided by Intel</a> that is pretty straightforward for developers who have C&#x2F;C++ experience.</li>\n<li>Performance analysis: Improving performance is the main purpose to use hardware intrinsic. <a href=\"https://benchmarkdotnet.org/articles/overview.html\">BecnmarkDotnet</a> is an open source profiler for .NET Core applications and it is easy to use. Meanwhile, I really like <a href=\"https://software.intel.com/en-us/vtune\">Intel VTune</a> that provides more sophisticated runtime hardware information, which is better for optimizing but understanding VTune output requires a bit of hardware knowledge.</li>\n<li>More hardware intrinsic examples:  the .NET Core community has leveraged intrinsics to optimize the library code in <a href=\"https://github.com/dotnet/corefx\">CoreFX</a> and <a href=\"https://github.com/dotnet/coreclr\">CoreCLR</a> repos, watching related issues and PRs on GitHub is a good approach to learn. For example, <a href=\"https://github.com/benaadams\">Ben Adams</a>‘s <a href=\"https://github.com/dotnet/coreclr/pull/22187#issuecomment-467872251\">PRs that vectorizing <code>IndexOf</code></a>. There are also some individual projects that heavily use hardware intrinsics, <a href=\"https://github.com/EgorBo/SimdJsonSharp\">SimdJsonSharp</a> is a C# port of SimdJson algorithm that accelerates JSON parsing using AVX2 instructions. <a href=\"https://github.com/fiigii/PacketTracer\">PacketTracer</a> is an SoA-vectorized ray tracing that is used to investigating .NET Core SIMD code generation quality.<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">PacketTracer is a SoA vectorized raytracer in .NET Core AVX intrinsic. We are using it to investigate CoreCLR SIMD code generation quality and it shows ~7x faster than the Vector3 AoS version. See <a href=\"https://t.co/ZHUmpvarwn\">https://t.co/ZHUmpvarwn</a> <a href=\"https://t.co/tHEqbijFNn\">pic.twitter.com/tHEqbijFNn</a></p>&mdash; Fei Peng (@fiigii) <a href=\"https://twitter.com/fiigii/status/1096512607471595520?ref_src=twsrc%5Etfw\">February 15, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script></li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/ADD.png","slug":"ADD.png","post":"clgj4x0br00019tne4sz6gw4u","modified":0,"renderable":0},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/LEA.png","slug":"LEA.png","post":"clgj4x0br00019tne4sz6gw4u","modified":0,"renderable":0},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS1.png","slug":"PRS1.png","post":"clgj4x0br00019tne4sz6gw4u","modified":0,"renderable":0},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS2.png","slug":"PRS2.png","post":"clgj4x0br00019tne4sz6gw4u","modified":0,"renderable":0},{"_id":"source/_posts/Does-register-selection-matter-to-performance-on-x86-CPUs/PRS3.png","slug":"PRS3.png","post":"clgj4x0br00019tne4sz6gw4u","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[{"post_id":"clgj4x0br00019tne4sz6gw4u","tag_id":"clgj4x0bt00049tne1dq3culz","_id":"clgj4x0bu00099tnehrfb4jdy"},{"post_id":"clgj4x0br00019tne4sz6gw4u","tag_id":"clgj4x0bu00069tnehzowfewc","_id":"clgj4x0bu000a9tne0797a9ut"},{"post_id":"clgj4x0br00019tne4sz6gw4u","tag_id":"clgj4x0bu00079tne6als45ut","_id":"clgj4x0bv000c9tneg8f8cidm"},{"post_id":"clgj4x0bt00039tne14vu7tzf","tag_id":"clgj4x0bu00089tne1bm30dm1","_id":"clgj4x0bv000e9tne25tody6u"},{"post_id":"clgj4x0bt00039tne14vu7tzf","tag_id":"clgj4x0bt00049tne1dq3culz","_id":"clgj4x0bv000f9tne9drj8ow1"},{"post_id":"clgj4x0bt00039tne14vu7tzf","tag_id":"clgj4x0bv000d9tnef0m7h8j5","_id":"clgj4x0bv000g9tne7cir1go0"}],"Tag":[{"name":"x86","_id":"clgj4x0bt00049tne1dq3culz"},{"name":"Compiler","_id":"clgj4x0bu00069tnehzowfewc"},{"name":"Intel","_id":"clgj4x0bu00079tne6als45ut"},{"name":".NET Core","_id":"clgj4x0bu00089tne1bm30dm1"},{"name":"SIMD","_id":"clgj4x0bv000d9tnef0m7h8j5"}]}}